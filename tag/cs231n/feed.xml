<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator>
  <link href="https://crosstar1228.github.io/tag/cs231n/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://crosstar1228.github.io/" rel="alternate" type="text/html" />
  <updated>2021-10-15T06:31:46+00:00</updated>
  <id>https://crosstar1228.github.io/tag/cs231n/feed.xml</id>

  
  
  

  
    <title type="html">건너별의 Romantic AI | </title>
  

  
    <subtitle>IT/인공지능 서랍장</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">내용 핵심요약! CS231n Lecture 3. Loss function and Optimization</title>
      <link href="https://crosstar1228.github.io/cs231n-lec3" rel="alternate" type="text/html" title="내용 핵심요약! CS231n Lecture 3.  Loss function and Optimization" />
      <published>2021-10-14T11:00:00+00:00</published>
      <updated>2021-10-14T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/cs231n-lec3</id>
      <content type="html" xml:base="https://crosstar1228.github.io/cs231n-lec3">&lt;h1 id=&quot;goal&quot;&gt;GOAL&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;parameter를 Loss function을 통해 update하는 &lt;em&gt;optimization&lt;/em&gt; 과정을 이해합니다.&lt;/li&gt;
  &lt;li&gt;Gradient descent 과정을 개괄적으로 이해합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#loss-function&quot;&gt;Loss function&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#multiclass-svm-loss&quot;&gt;Multiclass SVM Loss&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#regularization&quot;&gt;Regularization&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#Softmax-function&quot;&gt;Softmax function&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#optimization&quot;&gt;Optimization&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;loss-function&quot;&gt;Loss function&lt;/h2&gt;
&lt;p&gt;지난 시간에 우리는 Parameter를 update, 즉 최적의 가중치를 찾아내는 방법에 대한 필요성을 느꼈습니다.
한 마디로 이번 강의에서 설명할 최적화(Optimization)에 대한 이야기입니다. 그리고 그를 위한 핵심 개념인 손실 함수(Loss function)에 대하여 우선적으로 알아보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;what-is-loss-function&quot;&gt;What is loss function?&lt;/h3&gt;
&lt;p&gt;Loss function(손실 함수, 이하 한글 용어 생략)은 다른 말로 Cost function이라고 합니다.
Loss 또는 cost를 계산하는 함수다! 이렇게 예상이 되네요.
그리고 그러한 손실(또는 비용)이 줄어드는 것이 더 바람직한 방향이라는 감까지 오셨다면
Loss function에 대한 직관은 이미 반 정도 익히신 것으로 생각되네요. 조금더 자세히 들어다 볼까요?
&lt;img src=&quot;img.png&quot; alt=&quot;img.png&quot; /&gt;
우리는 위와 같은 이미지 분류 문제에서 진짜 class(label 또는 정답)에 해당하는 score가 가장 높은 점수가 나오도록 모델을 만들고 싶어요.
그래야만 새로운 이미지도 올바른 정답으로 판단할 확률이 높을 테니까요. 우리는 이것은 정확도(accuracy) 등의 지표로 판단하게 됩니다.
하지만 그림을 보면 고양이의 정답을 가진 사진은 deer(사슴)에 해당하는 가장 높은 점수를 갖고 있고, 개구리는 truck(트럭)에 해당하는 점수를 가장 높게 갖고 있네요.&lt;/p&gt;

&lt;p&gt;수치로 표현된 이러한 점수(score)들이 얼마나 바람직한지, &lt;strong&gt;정량적으로&lt;/strong&gt; 어긋난 정도를 판단할 필요성을 느낍니다.
그 벗어난 정도를 알아야 알맞게 가중치를 갱신할 수 있기 때문입니다.
정량적인 수치로 표현해야 하니, 특정한 입력값마다 변하는 하나의 함수가 정의되는 것이고,
그것이 Loss function으로 표현되는 것입니다.
&lt;img src=&quot;img_3.png&quot; alt=&quot;img_3.png&quot; /&gt;
&lt;img src=&quot;img_1.png&quot; alt=&quot;img_1.png&quot; /&gt;
$f(x_i, W)$ : input과 parameter에 의한 예측된 score를 의미합니다.
$y_i$ : label, 즉 정답에 해당하는 score를 의미합니다. 분류 문제에서는 정답의 class가 1, 나머지는 0으로 기록되어 있습니다.&lt;/p&gt;

&lt;p&gt;두 값의 차이가 N개의 data별로 각각 존재할 것이고, 그것을 평균낸 값을 우리는 $L(W)$로 정의하는 것입니다. 
$W$, 즉 parameter가 독립변수로 존재하는 함수이니, 이 값에 따라 Loss function의 결괏값도 달라지지라는 것을 직관적으로 이해할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이러한 Loss function의 예시인 Multiclass SVM Loss 를 살펴보며 이해도를 높여 보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;multiclass-svm-loss&quot;&gt;Multiclass SVM Loss&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;img_2.png&quot; alt=&quot;img_2.png&quot; /&gt;
 이전에 편의상 score라고 표현한 예측값이 여기서 정식으로 정의됩니다.
그리고 $L_i$는 다음과 같이 정의돼요!&lt;/p&gt;

\[$L_i = \underset{j\not=y_i}\sum$
\begin{cases}0 \qquad\qquad\qquad if\quad s_{y_i}\geq s_j + 1\\s_j - s_{y_i} + 1\quad \: if\quad otherwise
\end{cases}\]

&lt;p&gt;\($= \underset{j\not=y_i}\sum max(0,s_j - s_{y_i} + 1 )$\)&lt;/p&gt;
&lt;h3 id=&quot;regularization&quot;&gt;Regularization&lt;/h3&gt;

&lt;h3 id=&quot;softmax-function&quot;&gt;Softmax function&lt;/h3&gt;

&lt;h2 id=&quot;optimization&quot;&gt;Optimization&lt;/h2&gt;
&lt;h3 id=&quot;stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/h3&gt;</content>

      
      
      
      
      

      <author>
          <name>건너별(crosstar)</name>
        
        
      </author>

      

      
        <category term="cs231n" />
      

      
        <summary type="html">GOAL parameter를 Loss function을 통해 update하는 optimization 과정을 이해합니다. Gradient descent 과정을 개괄적으로 이해합니다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">CS231n Lecture 12. Visualizing and understanding</title>
      <link href="https://crosstar1228.github.io/cs231n-lec12" rel="alternate" type="text/html" title="CS231n Lecture 12. Visualizing and understanding" />
      <published>2021-09-16T11:00:00+00:00</published>
      <updated>2021-09-16T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/cs231n-lec12</id>
      <content type="html" xml:base="https://crosstar1228.github.io/cs231n-lec12">&lt;h1 id=&quot;goal&quot;&gt;GOAL&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;시각화를 통해 CNN의 feature를 이해하는 방법론들을 activation과 gradient의 관점에서 알아본다.&lt;/li&gt;
  &lt;li&gt;이미지 Style을 변형시키는 방법에 대해 알아본다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#deepdream&quot;&gt;Deepdream&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#feature-inversion&quot;&gt;Feature Inversion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#texture-synthesis&quot;&gt;Texture Synthesis&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#gram-matrix&quot;&gt;Gram Matrix&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#style-transfer&quot;&gt;Style Transfer&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#fast-style-transfer&quot;&gt;Fast Style Trnasfer&lt;/a&gt;
        &lt;h2 id=&quot;layers&quot;&gt;Layers&lt;/h2&gt;
      &lt;/li&gt;
      &lt;li&gt;first layer&lt;/li&gt;
      &lt;li&gt;last layer -&amp;gt; feature nearest&lt;/li&gt;
      &lt;li&gt;t-SNE dimensionality reduction
        &lt;h2 id=&quot;deepdream&quot;&gt;Deepdream&lt;/h2&gt;
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; - [위키백과 : Deepdream](https://en.wikipedia.org/wiki/DeepDream)  
 - [이미지 사이트 체험](https://deepdreamgenerator.com/)
 - Google 에서 만든 재미용
 - network의 중간에 **특정한 neuron activation을 Amplify(증폭)**  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;-&amp;gt; 네트워크가 이미 뽑아낸 특징들을 더욱 증폭시키는 역할&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;원리
    &lt;ol&gt;
      &lt;li&gt;forward 방향으로 activation 계산 (여기까진 일반적 네트워크와 같음)&lt;/li&gt;
      &lt;li&gt;layer의 &lt;strong&gt;&lt;em&gt;activation 과 같은&lt;/em&gt; gradient를 설정&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;Backward 방향으로 gradient 계산 (backprop)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;결과를 위해 조정한 사항들
    &lt;ol&gt;
      &lt;li&gt;Jitter : 이미지를 두 픽셀씩 옮김&lt;/li&gt;
      &lt;li&gt;Normalize ascent to gradient&lt;/li&gt;
      &lt;li&gt;Clip pixel values :최대,최솟값으로 제한&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;-&amp;gt; training 되었던 image들의 feature들이 input image에 함께 뒤섞여 나타남
&lt;img src=&quot;../../assets/built/images/img_1.png&quot; alt=&quot;img_1.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;feature-inversion&quot;&gt;feature Inversion&lt;/h2&gt;

&lt;p&gt;이미지의 CNN feature Vector 가 주어졌을 때&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;자연스럽고&lt;/li&gt;
  &lt;li&gt;그 feature vector 가장 잘 부합하는&lt;br /&gt;
&lt;strong&gt;이미지 output return&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_2.png&quot; alt=&quot;img_2.png&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;주어진 feature vector와&lt;/li&gt;
  &lt;li&gt;새로운 이미지의 feature와의 L2 distance 측정 &lt;br /&gt;
Regularization 진행 후 &lt;strong&gt;최솟값을 return&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_3.png&quot; alt=&quot;img_3.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;VGG16의 각기 다른 layer로부터 feature inversion 진행 결과,&lt;br /&gt;
  -&amp;gt; 얕은 layer보다는 깊은 layer에서 더 새로운 output이 탄생함을 알 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;texture-synthesis&quot;&gt;Texture Synthesis&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Sample patch(이미지 일부)로부터 같은 texture의 더 큰 이미지 합성하는 방식&lt;/li&gt;
  &lt;li&gt;nearest neighbor 알고리즘으로 ‘복붙’하면 깨짐 현상이 있음&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gram-matrix&quot;&gt;Gram matrix&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;image의 질감의 유사도를 표현하는 행렬, 이를 통해 texture synthesis 진행&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_4.png&quot; alt=&quot;img_4.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;원리&lt;br /&gt;
1) image input을 CNN에 넣으면 C*H*W tensor가 출력됨&lt;br /&gt;
2) 이 tensor 중 2개의 C차원 vector를 외적하면 C*C의 co-occurence를 표현하는 matrix가 나오는데 이것이 바로 Gram matrix&lt;br /&gt;
3) 마치 covariance을 판단하는 행렬 -&amp;gt; 질감의 유사도를 측정 가능!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gram-matrix-이용한-합성과정&quot;&gt;Gram matrix 이용한 합성과정&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_5.png&quot; alt=&quot;img_5.png&quot; /&gt;
1) 하나는 input으로부터, 하나는 Noise로부터 이미지를 생성&lt;br /&gt;
2) Gram matrix 추출 후 Gram matrix 간에 L2 distance의 가중합, 즉 Loss 계산&lt;br /&gt;
3) Gradient 계산을 위한 Backprop 및 parameter update(make gradient step)&lt;br /&gt;
4) 2)~3) 반복
&lt;img src=&quot;../../assets/built/images/img9.png&quot; alt=&quot;img9.png&quot; /&gt;
-&amp;gt; 이 기법 역시 깊은 Layer로부터 더 많은 feature들이 추출됨을 알 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;style-transfer&quot;&gt;Style Transfer&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;비슷한 방법으로 두 이미지의 texture 차이를 최소화함으로서 특정 이미지의 분위기 합성이 가능
-&amp;gt; Style transfer&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Gram matrix값 최소화시키면서 생성하는 이미지 기법
&lt;img src=&quot;../../assets/built/images/img_6.png&quot; alt=&quot;img_6.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Content image, Style image&lt;/strong&gt;
1) content image로부터 feature reconstruction&lt;br /&gt;
2) style image로부터 gram matrix reconstruction&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;특징&lt;/strong&gt;
1) Fine control 가능(style image 크기 조정 등)&lt;br /&gt;
2) forward/backward prop 과정이 너무 많아서 느림.&lt;/p&gt;

    &lt;p&gt;-&amp;gt; style transfer를 진행하는 또 하나의 Neural Network를 구현하자!&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;fast-style-transfer&quot;&gt;Fast style Transfer&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_8.png&quot; alt=&quot;img_8.png&quot; /&gt;
1) style을 미리 &lt;strong&gt;Feedforward Network \(f_W\) 에 학습&lt;/strong&gt;시킴&lt;br /&gt;
2) content image만 feed forward -&amp;gt; &lt;strong&gt;속도 향상&lt;/strong&gt;&lt;br /&gt;
   ** batch normalization보다 instant normalization 에서 더 큰 상승 효과&lt;br /&gt;
    &lt;img src=&quot;../../assets/built/images/img9.png&quot; alt=&quot;img.png&quot; /&gt;
3) segmentation network는 여러 층으로 transposed convolution 이용해서 down,upsampling&lt;/p&gt;

&lt;h3 id=&quot;deepdream-website에서-style-transfer-통해-쇠라풍-그림으로-교체한-사진&quot;&gt;Deepdream website에서 Style transfer 통해 쇠라풍 그림으로 교체한 사진&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_7.png&quot; alt=&quot;img_7.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;CS231n 12강 Lecture Note : http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture12.pdf&lt;/li&gt;
  &lt;li&gt;https://inhovation97.tistory.com/28&lt;/li&gt;
  &lt;li&gt;style transfer : https://www.popit.kr/neural-style-transfer-%EB%94%B0%EB%9D%BC%ED%95%98%EA%B8%B0/&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>건너별(crosstar)</name>
        
        
      </author>

      

      
        <category term="cs231n" />
      

      
        <summary type="html">GOAL 시각화를 통해 CNN의 feature를 이해하는 방법론들을 activation과 gradient의 관점에서 알아본다. 이미지 Style을 변형시키는 방법에 대해 알아본다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">CS231n Lecture 3. Neural Network</title>
      <link href="https://crosstar1228.github.io/cs231n-lec3" rel="alternate" type="text/html" title="CS231n Lecture 3.  Neural Network" />
      <published>2021-09-15T11:00:00+00:00</published>
      <updated>2021-09-15T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/cs231n-lec3</id>
      <content type="html" xml:base="https://crosstar1228.github.io/cs231n-lec3">&lt;h1 id=&quot;안녕&quot;&gt;안녕&lt;/h1&gt;
&lt;p&gt;cs231n&lt;/p&gt;

&lt;p&gt;강의 잘하고싶다.~~~~~~~~~~!!!!!!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;진짜로.&lt;/strong&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;후&lt;/code&gt;…&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>건너별(crosstar)</name>
        
        
      </author>

      

      
        <category term="cs231n" />
      

      
        <summary type="html">안녕 cs231n</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">CS231n Lecture 3. Neural Network</title>
      <link href="https://crosstar1228.github.io/cs231n-lec2" rel="alternate" type="text/html" title="CS231n Lecture 3.  Neural Network" />
      <published>2021-09-15T11:00:00+00:00</published>
      <updated>2021-09-15T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/cs231n-lec2</id>
      <content type="html" xml:base="https://crosstar1228.github.io/cs231n-lec2">&lt;h1 id=&quot;안녕&quot;&gt;안녕&lt;/h1&gt;
&lt;p&gt;cs231n&lt;/p&gt;

&lt;p&gt;강의 잘하고싶다.~~~~~~~~~~!!!!!!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;진짜로.&lt;/strong&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;후&lt;/code&gt;…&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>건너별(crosstar)</name>
        
        
      </author>

      

      
        <category term="cs231n" />
      

      
        <summary type="html">안녕 cs231n</summary>
      

      
      
    </entry>
  
</feed>
