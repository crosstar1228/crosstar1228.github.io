<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator>
  <link href="https://crosstar1228.github.io/tag/cs231n/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://crosstar1228.github.io/" rel="alternate" type="text/html" />
  <updated>2021-09-26T10:52:26+00:00</updated>
  <id>https://crosstar1228.github.io/tag/cs231n/feed.xml</id>

  
  
  

  
    <title type="html">건너별의 Romantic AI | </title>
  

  
    <subtitle>IT/인공지능 서랍장</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">CS231n Lecture 12. Visualizing and understanding</title>
      <link href="https://crosstar1228.github.io/cs231n-lec12" rel="alternate" type="text/html" title="CS231n Lecture 12. Visualizing and understanding" />
      <published>2021-09-15T11:00:00+00:00</published>
      <updated>2021-09-15T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/cs231n-lec12</id>
      <content type="html" xml:base="https://crosstar1228.github.io/cs231n-lec12">&lt;h1 id=&quot;goal&quot;&gt;GOAL&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;시각화를 통해 CNN의 feature를 이해하는 방법론들을 activation과 gradient의 관점에서 알아본다.&lt;/li&gt;
  &lt;li&gt;이미지 Style을 변형시키는 방법에 대해 알아본다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#deepdream&quot;&gt;Deepdream&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#feature-inversion&quot;&gt;Feature Inversion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#texture-synthesis&quot;&gt;Texture Synthesis&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#gram-matrix&quot;&gt;Gram Matrix&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#style-transfer&quot;&gt;Style Transfer&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#fast-style-transfer&quot;&gt;Fast Style Trnasfer&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;deepdream&quot;&gt;Deepdream&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/DeepDream&quot;&gt;위키백과 : Deepdream&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://deepdreamgenerator.com/&quot;&gt;이미지 사이트 체험&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Google 에서 만든 재미용&lt;/li&gt;
  &lt;li&gt;network의 중간에 &lt;strong&gt;특정한 neuron activation을 Amplify(증폭)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;-&amp;gt; 네트워크가 이미 뽑아낸 특징들을 더욱 증폭시키는 역할&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;원리
1) forward 방향으로 activation 계산 (여기까진 일반적 네트워크와 같음)
2) layer의 &lt;strong&gt;&lt;em&gt;activation 과 같은&lt;/em&gt; gradient를 설정&lt;/strong&gt; 
3) Backward 방향으로 gradient 계산 (backprop)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;결과를 위해 조정한 사항들&lt;br /&gt;
1) Jitter : 이미지를 두 픽셀씩 옮김
2) Normalize ascent to gradient 
3) Clip pixel values :최대,최솟값으로 제한&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;-&amp;gt; training 되었던 image들의 feature들이 input image에 함께 뒤섞여 나타남
&lt;img src=&quot;../../assets/built/images/img_1.png&quot; alt=&quot;img_1.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;feature-inversion&quot;&gt;feature Inversion&lt;/h2&gt;

&lt;p&gt;이미지의 CNN feature Vector 가 주어졌을 때&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;자연스럽고&lt;/li&gt;
  &lt;li&gt;그 feature vector 가장 잘 부합하는&lt;br /&gt;
이미지 output return&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_2.png&quot; alt=&quot;img_2.png&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;주어진 feature vector와&lt;/li&gt;
  &lt;li&gt;새로운 이미지의 feature와의 L2 distance 측정 &lt;br /&gt;
Regularization 진행 후 &lt;strong&gt;최솟값을 return&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_3.png&quot; alt=&quot;img_3.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;VGG16의 각기 다른 layer로부터 feature inversion 진행 결과,
  -&amp;gt; 얕은 layer보다는 깊은 layer에서 더 새로운 output이 탄생함을 알 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;texture-synthesis&quot;&gt;Texture Synthesis&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Sample patch(이미지 일부)로부터 같은 texture의 더 큰 이미지 합성하는 방식&lt;/li&gt;
  &lt;li&gt;nearest neighbor 알고리즘으로 ‘복붙’하면 깨짐 현상이 있음&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gram-matrix&quot;&gt;Gram matrix&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;image의 질감을 표현하는 행렬, 이를 통해 text synthesis 진행&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_4.png&quot; alt=&quot;img_4.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;원리
1) image input을 CNN에 넣으면 C&lt;em&gt;H&lt;/em&gt;W tensor가 출력됨&lt;br /&gt;
2) 이 tensor 중 2개의 C차원 vector를 외적하면 C*C의 co-occurence를 표현하는 matrix가 나오는데 이것이 바로 Gram matrix&lt;br /&gt;
3) 마치 correlation을 판단하는 행렬 -&amp;gt; 질감의 유사도를 측정 가능!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gram-matrix-이용한-합성과정&quot;&gt;Gram matrix 이용한 합성과정&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_5.png&quot; alt=&quot;img_5.png&quot; /&gt;
1) 하나는 input으로부터, 하나는 Noise로부터 이미지를 생성&lt;br /&gt;
2) Gram matrix 추출 후 Gram matrix 간에 L2 distance의 가중합, 즉 Loss 계산&lt;br /&gt;
3) Gradient 계산을 위한 Backprop 및 parameter update(make gradient step)&lt;br /&gt;
4) 2)~3) 반복&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;이 기법 역시 깊은 Layer로부터 더 많은 feature들이 추출됨을 알 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;style-transfer&quot;&gt;Style Transfer&lt;/h2&gt;
&lt;p&gt;비슷한 방법으로 두 이미지의 texture 차이를 최소화함으로서 특정 이미지의 분위기 합성이 가능
-&amp;gt; Style transfer&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Gram matrix값 최소화시키면서 생성하는 이미지 기법
&lt;img src=&quot;../../assets/built/images/img_6.png&quot; alt=&quot;img_6.png&quot; /&gt;
    &lt;h3 id=&quot;content-image-style-image&quot;&gt;Content image, Style image&lt;/h3&gt;
    &lt;p&gt;1) content image로부터 feature reconstruction&lt;br /&gt;
2) style image로부터 gram matrix reconstruction&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;특징&quot;&gt;특징&lt;/h3&gt;
&lt;p&gt;1) Fine control 가능(style image 크기 조정 등)&lt;br /&gt;
2) 너무 느림.&lt;/p&gt;

&lt;h3 id=&quot;fast-style-transfer&quot;&gt;Fast style Transfer&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_8.png&quot; alt=&quot;img_8.png&quot; /&gt;
1) style을 미리 &lt;strong&gt;Feedforward Network \(f_W\) 에 학습&lt;/strong&gt;시킴&lt;br /&gt;
2) content image만 feed forward -&amp;gt; &lt;strong&gt;속도 향상&lt;/strong&gt;
   ** batch normalization보다 instant normalization 에서 더 큰 상승 효과&lt;br /&gt;
3) segmentation network는 여러 층으로 transposed convolution 이용해서 down,upsampling&lt;/p&gt;

&lt;h3 id=&quot;deepdream-website에서-style-transfer-통해-쇠라풍-그림으로-교체한-사진&quot;&gt;Deepdream website에서 Style transfer 통해 쇠라풍 그림으로 교체한 사진&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_7.png&quot; alt=&quot;img_7.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;CS231n 12강 Lecture Note : http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture12.pdf&lt;/li&gt;
  &lt;li&gt;https://inhovation97.tistory.com/28&lt;/li&gt;
  &lt;li&gt;style transfer : https://www.popit.kr/neural-style-transfer-%EB%94%B0%EB%9D%BC%ED%95%98%EA%B8%B0/&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>건너별(crosstar)</name>
        
        
      </author>

      

      
        <category term="cs231n" />
      

      
        <summary type="html">GOAL 시각화를 통해 CNN의 feature를 이해하는 방법론들을 activation과 gradient의 관점에서 알아본다. 이미지 Style을 변형시키는 방법에 대해 알아본다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">CS231n Lecture 12. Visualizing and understanding</title>
      <link href="https://crosstar1228.github.io/cs231n-lec12" rel="alternate" type="text/html" title="CS231n Lecture 12. Visualizing and understanding" />
      <published>2021-09-15T11:00:00+00:00</published>
      <updated>2021-09-15T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/cs231n-lec12</id>
      <content type="html" xml:base="https://crosstar1228.github.io/cs231n-lec12">&lt;p&gt;window 10 에서 git bash를 통해 repository로 push하던 중&lt;/p&gt;
&lt;h3 id=&quot;문제&quot;&gt;문제&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;fatal: authetication failed for ---
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;위와 같은 오류로 명령어 실행이 거부되었다.&lt;/p&gt;

&lt;h3 id=&quot;원인-및-해결&quot;&gt;원인 및 해결&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;계정 정보가 수정된 것이 local 환경에 반영이 안된 것이다.&lt;br /&gt;
이럴 때는 아래 명령어로 reset 한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;﻿$ git config --system --unset credential.helper
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이때 아래처럼 에러가 나는 경우가 또 있다.&lt;/p&gt;

&lt;h3 id=&quot;문제-1&quot;&gt;문제&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;﻿error: could not lock config file C:/Program Files/Git/etc/gitconfig: Permission denied
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;원인-및-해결-1&quot;&gt;원인 및 해결&lt;/h3&gt;
&lt;p&gt;이럴땐 &lt;strong&gt;git bash를 관리자 권한으로 실행&lt;/strong&gt;하여 해당 폴더로 이동 후 명령어를 다시 실행하면 된다.&lt;/p&gt;

&lt;p&gt;++ push 시 뜨는 계정 비밀번호 입력은 &lt;strong&gt;token&lt;/strong&gt;으로 하는 걸 잊지 말자!&lt;/p&gt;

&lt;p&gt;끝!&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>건너별(crosstar)</name>
        
        
      </author>

      

      
        <category term="cs231n" />
      

      
        <summary type="html">window 10 에서 git bash를 통해 repository로 push하던 중 문제 fatal: authetication failed for --- 위와 같은 오류로 명령어 실행이 거부되었다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">CS231n Lecture 3. Neural Network</title>
      <link href="https://crosstar1228.github.io/cs231n-lec2" rel="alternate" type="text/html" title="CS231n Lecture 3.  Neural Network" />
      <published>2021-09-15T11:00:00+00:00</published>
      <updated>2021-09-15T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/cs231n-lec2</id>
      <content type="html" xml:base="https://crosstar1228.github.io/cs231n-lec2">&lt;h1 id=&quot;안녕&quot;&gt;안녕&lt;/h1&gt;
&lt;p&gt;cs231n&lt;/p&gt;

&lt;p&gt;강의 잘하고싶다.~~~~~~~~~~!!!!!!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;진짜로.&lt;/strong&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;후&lt;/code&gt;…&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>건너별(crosstar)</name>
        
        
      </author>

      

      
        <category term="cs231n" />
      

      
        <summary type="html">안녕 cs231n</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">CS231n Lecture 2. Linear Classifier</title>
      <link href="https://crosstar1228.github.io/cs231n-lec1" rel="alternate" type="text/html" title="CS231n Lecture 2.  Linear Classifier" />
      <published>2021-09-15T11:00:00+00:00</published>
      <updated>2021-09-15T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/cs231n-lec1</id>
      <content type="html" xml:base="https://crosstar1228.github.io/cs231n-lec1">&lt;h1 id=&quot;안녕&quot;&gt;안녕&lt;/h1&gt;
&lt;p&gt;cs231n 강의 잘하고싶다.~~~~~~~~~~!!!!!!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;진짜로.&lt;/strong&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;후&lt;/code&gt;…&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>건너별(crosstar)</name>
        
        
      </author>

      

      
        <category term="cs231n" />
      

      
        <summary type="html">안녕 cs231n 강의 잘하고싶다.~~~~~~~~~~!!!!!!</summary>
      

      
      
    </entry>
  
</feed>
