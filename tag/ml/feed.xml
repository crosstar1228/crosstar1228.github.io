<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator>
  <link href="https://crosstar1228.github.io/tag/ml/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://crosstar1228.github.io/" rel="alternate" type="text/html" />
  <updated>2022-07-30T12:35:19+00:00</updated>
  <id>https://crosstar1228.github.io/tag/ml/feed.xml</id>

  
  
  

  
    <title type="html">ê±´ë„ˆë³„ì˜ Romantic AI | </title>
  

  
    <subtitle>IT/ì¸ê³µì§€ëŠ¥ ì„œëì¥</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">Generative Modelì˜ ì‹ í¥ê°•ì, Diffusion Model!</title>
      <link href="https://crosstar1228.github.io/ML-Diffusion_Model" rel="alternate" type="text/html" title="Generative Modelì˜ ì‹ í¥ê°•ì, Diffusion Model!" />
      <published>2022-07-29T11:00:00+00:00</published>
      <updated>2022-07-29T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/ML-Diffusion_Model</id>
      <content type="html" xml:base="https://crosstar1228.github.io/ML-Diffusion_Model">&lt;h3 id=&quot;diffusion-model&quot;&gt;Diffusion Model&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Markov Chain ì„ ì‚¬ìš©í•œ Latent variable model&lt;/li&gt;
  &lt;li&gt;priorë¡œë¶€í„° posteriorë¥¼ ì–»ê¸° ìœ„í•˜ì—¬ x1,x2, xT ì˜ ê° time point ë³„ latent varibleì— noiseë¥¼ ë”í•´ê°€ëŠ” êµ¬ì¡°&lt;/li&gt;
  &lt;li&gt;ê²°ê³¼ì ìœ¼ë¡œ Gaussian noiseë¥¼ ë ê²Œ ë¨&lt;/li&gt;
  &lt;li&gt;ì´ì˜ ì—­ë³€í™˜ ê³¼ì •ìœ¼ë¡œ ìƒˆë¡œìš´ dataë¥¼ ìƒì„±&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;benefits&quot;&gt;Benefits&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;scalability&lt;/li&gt;
  &lt;li&gt;parallelizabliity&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;process&quot;&gt;process&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;forward process&lt;/li&gt;
  &lt;li&gt;reverse process&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;objective-function&quot;&gt;objective function&lt;/h3&gt;
&lt;p&gt;log likelihoodë¥¼ ì‚¬ìš©í•˜ë©°, ì´ˆê¸° ì´ë¯¸ì§€ì˜ í™•ë¥ ë¶„í¬ì™€ ë³µì›ëœ ì´ë¯¸ì§€ì˜ í™•ë¥ ë¶„í¬ ê°„ KL Divergence&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/&lt;/li&gt;
  &lt;li&gt;https://arxiv.org/pdf/2006.11239.pdf&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>ê±´ë„ˆë³„(crosstar)</name>
        
        
      </author>

      

      
        <category term="ML" />
      

      
        <summary type="html">Diffusion Model Markov Chain ì„ ì‚¬ìš©í•œ Latent variable model priorë¡œë¶€í„° posteriorë¥¼ ì–»ê¸° ìœ„í•˜ì—¬ x1,x2, xT ì˜ ê° time point ë³„ latent varibleì— noiseë¥¼ ë”í•´ê°€ëŠ” êµ¬ì¡° ê²°ê³¼ì ìœ¼ë¡œ Gaussian noiseë¥¼ ë ê²Œ ë¨ ì´ì˜ ì—­ë³€í™˜ ê³¼ì •ìœ¼ë¡œ ìƒˆë¡œìš´ dataë¥¼ ìƒì„±</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">ë‚´ìš© í•µì‹¬ìš”ì•½! CS231n Lecture 4. Backpropagation</title>
      <link href="https://crosstar1228.github.io/ML-marcov_chain" rel="alternate" type="text/html" title="ë‚´ìš© í•µì‹¬ìš”ì•½! CS231n Lecture 4.  Backpropagation" />
      <published>2021-10-14T11:00:00+00:00</published>
      <updated>2021-10-14T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/ML-marcov_chain</id>
      <content type="html" xml:base="https://crosstar1228.github.io/ML-marcov_chain">&lt;h1 id=&quot;goal&quot;&gt;GOAL&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;parameterë¥¼ Loss functionì„ í†µí•´ updateí•˜ëŠ” &lt;em&gt;optimization&lt;/em&gt; ê³¼ì •ì„ ì´í•´í•©ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;Gradient descent ê³¼ì •ì„ ê°œê´„ì ìœ¼ë¡œ ì´í•´í•©ë‹ˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#loss-function&quot;&gt;Loss function&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#multiclass-svm-loss&quot;&gt;Multiclass SVM Loss&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#regularization&quot;&gt;Regularization&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#Softmax-function&quot;&gt;Softmax function&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#optimization&quot;&gt;Optimization&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;loss-function&quot;&gt;Loss function&lt;/h2&gt;
&lt;p&gt;ì§€ë‚œ ì‹œê°„ì— ìš°ë¦¬ëŠ” Parameterë¥¼ update, ì¦‰ ìµœì ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì°¾ì•„ë‚´ëŠ” ë°©ë²•ì— ëŒ€í•œ í•„ìš”ì„±ì„ ëŠê¼ˆìŠµë‹ˆë‹¤.
í•œ ë§ˆë””ë¡œ ì´ë²ˆ ê°•ì˜ì—ì„œ ì„¤ëª…í•  ìµœì í™”(Optimization)ì— ëŒ€í•œ ì´ì•¼ê¸°ì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ë¥¼ ìœ„í•œ í•µì‹¬ ê°œë…ì¸ ì†ì‹¤ í•¨ìˆ˜(Loss function)ì— ëŒ€í•˜ì—¬ ìš°ì„ ì ìœ¼ë¡œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;what-is-loss-function&quot;&gt;What is loss function?&lt;/h3&gt;
&lt;p&gt;Loss function(ì†ì‹¤ í•¨ìˆ˜, ì´í•˜ í•œê¸€ ìš©ì–´ ìƒëµ)ì€ ë‹¤ë¥¸ ë§ë¡œ Cost functionì´ë¼ê³  í•©ë‹ˆë‹¤.
Loss ë˜ëŠ” costë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë‹¤! ì´ë ‡ê²Œ ì˜ˆìƒì´ ë˜ë„¤ìš”.
ê·¸ë¦¬ê³  ê·¸ëŸ¬í•œ ì†ì‹¤(ë˜ëŠ” ë¹„ìš©)ì´ ì¤„ì–´ë“œëŠ” ê²ƒì´ ë” ë°”ëŒì§í•œ ë°©í–¥ì´ë¼ëŠ” ê°ê¹Œì§€ ì˜¤ì…¨ë‹¤ë©´
Loss functionì— ëŒ€í•œ ì§ê´€ì€ ì´ë¯¸ ë°˜ ì •ë„ ìµíˆì‹  ê²ƒìœ¼ë¡œ ìƒê°ë˜ë„¤ìš”. ì¡°ê¸ˆë” ìì„¸íˆ ë“¤ì–´ë‹¤ ë³¼ê¹Œìš”?
&lt;img src=&quot;../../assets/built/images/lec3_img.png&quot; alt=&quot;img.png&quot; /&gt;
ìš°ë¦¬ëŠ” ìœ„ì™€ ê°™ì€ ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì§„ì§œ class(label ë˜ëŠ” ì •ë‹µ)ì— í•´ë‹¹í•˜ëŠ” scoreê°€ ê°€ì¥ ë†’ì€ ì ìˆ˜ê°€ ë‚˜ì˜¤ë„ë¡ ëª¨ë¸ì„ ë§Œë“¤ê³  ì‹¶ì–´ìš”.
ê·¸ë˜ì•¼ë§Œ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë„ ì˜¬ë°”ë¥¸ ì •ë‹µìœ¼ë¡œ íŒë‹¨í•  í™•ë¥ ì´ ë†’ì„ í…Œë‹ˆê¹Œìš”. ìš°ë¦¬ëŠ” ì´ê²ƒì€ ì •í™•ë„(accuracy) ë“±ì˜ ì§€í‘œë¡œ íŒë‹¨í•˜ê²Œ ë©ë‹ˆë‹¤.
í•˜ì§€ë§Œ ê·¸ë¦¼ì„ ë³´ë©´ ê³ ì–‘ì´ì˜ ì •ë‹µì„ ê°€ì§„ ì‚¬ì§„ì€ deer(ì‚¬ìŠ´)ì— í•´ë‹¹í•˜ëŠ” ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°–ê³  ìˆê³ , ê°œêµ¬ë¦¬ëŠ” truck(íŠ¸ëŸ­)ì— í•´ë‹¹í•˜ëŠ” ì ìˆ˜ë¥¼ ê°€ì¥ ë†’ê²Œ ê°–ê³  ìˆë„¤ìš”.&lt;/p&gt;

&lt;p&gt;ìˆ˜ì¹˜ë¡œ í‘œí˜„ëœ ì´ëŸ¬í•œ ì ìˆ˜(score)ë“¤ì´ ì–¼ë§ˆë‚˜ ë°”ëŒì§í•œì§€, &lt;strong&gt;ì •ëŸ‰ì ìœ¼ë¡œ&lt;/strong&gt; ì–´ê¸‹ë‚œ ì •ë„ë¥¼ íŒë‹¨í•  í•„ìš”ì„±ì„ ëŠë‚ë‹ˆë‹¤.
ê·¸ ë²—ì–´ë‚œ ì •ë„ë¥¼ ì•Œì•„ì•¼ ì•Œë§ê²Œ ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
ì •ëŸ‰ì ì¸ ìˆ˜ì¹˜ë¡œ í‘œí˜„í•´ì•¼ í•˜ë‹ˆ, íŠ¹ì •í•œ ì…ë ¥ê°’ë§ˆë‹¤ ë³€í•˜ëŠ” í•˜ë‚˜ì˜ í•¨ìˆ˜ê°€ ì •ì˜ë˜ëŠ” ê²ƒì´ê³ ,
ê·¸ê²ƒì´ Loss functionìœ¼ë¡œ í‘œí˜„ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
&lt;img src=&quot;../../assets/built/images/lec3_img_3.png&quot; alt=&quot;img_3.png&quot; /&gt;
&lt;img src=&quot;../../assets/built/images/lec3_img_1.png&quot; alt=&quot;img_1.png&quot; /&gt;
$f(x_i, W)$ : inputê³¼ parameterì— ì˜í•œ ì˜ˆì¸¡ëœ scoreë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.&lt;br /&gt;
$y_i$ : label, ì¦‰ ì •ë‹µì— í•´ë‹¹í•˜ëŠ” scoreë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ë¶„ë¥˜ ë¬¸ì œì—ì„œëŠ” ì •ë‹µì˜ classê°€ 1, ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ ê¸°ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë‘ ê°’ì˜ ì°¨ì´ê°€ Nê°œì˜ dataë³„ë¡œ ê°ê° ì¡´ì¬í•  ê²ƒì´ê³ , ê·¸ê²ƒì„ í‰ê· ë‚¸ ê°’ì„ ìš°ë¦¬ëŠ” $L(W)$ë¡œ ì •ì˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 
$W$, ì¦‰ parameterê°€ ë…ë¦½ë³€ìˆ˜ë¡œ ì¡´ì¬í•˜ëŠ” í•¨ìˆ˜ì´ë‹ˆ, ì´ ê°’ì— ë”°ë¼ Loss functionì˜ ê²°ê´ê°’ë„ ë‹¬ë¼ì§€ì§€ë¼ëŠ” ê²ƒì„ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ëŸ¬í•œ Loss functionì˜ ì˜ˆì‹œì¸ Multiclass SVM Loss ë¥¼ ì‚´í´ë³´ë©° ì´í•´ë„ë¥¼ ë†’ì—¬ ë³´ê² ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;multiclass-svm-loss&quot;&gt;Multiclass SVM Loss&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/lec3_img_2.png&quot; alt=&quot;img_2.png&quot; /&gt;
 ì´ì „ì— í¸ì˜ìƒ scoreë¼ê³  í‘œí˜„í•œ ì˜ˆì¸¡ê°’ì´ ì—¬ê¸°ì„œ ì •ì‹ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤.
ê·¸ë¦¬ê³  $L_i$ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ë¼ìš”!&lt;/p&gt;

&lt;p&gt;$L_i = \underset{j\not=y_i} \sum$
\(\begin{cases}0 \qquad\qquad\qquad if\quad s_{y_i}\geq s_j + 1\\s_j - s_{y_i} + 1\quad \: if\quad otherwise
\end{cases}\)&lt;/p&gt;

&lt;p&gt;ë‹¤ì‹œ ì“°ìë©´,&lt;/p&gt;

&lt;p&gt;$L_i = \underset{j\not=y_i} \sum max(0, s_j - s_{y_i} + 1 )$&lt;/p&gt;

&lt;p&gt;$s_j$ : jë²ˆì§¸ class score&lt;br /&gt;
$s_{y_i}$ : ì •ë‹µ(label)ì— í•´ë‹¹í•˜ëŠ” score&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;ì–´ë–¤ ìˆ˜ì‹ì„ ì´í•´í•˜ëŠ”ë° ìµœìš°ì„ ì¸ ì§ê´€ë¶€í„° ê°€ì ¸ê°€ ë´…ì‹œë‹¤.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;0ê³¼ &lt;strong&gt;íŠ¹ì •í•œ ê°’&lt;/strong&gt;ì¤‘ì—ì„œ ìµœëŒ€ë¥¼ ê³¨ë¼ìš”. ê·¸ íŠ¹ì •í•œ ê°’ì´ë¼ëŠ” ê²ƒì€&lt;/li&gt;
  &lt;li&gt;(jë²ˆì§¸ class score) - (ì •ë‹µì— í•´ë‹¹í•˜ëŠ” class score) ë¥¼ êµ¬í•˜ê³  ê·¸ê²ƒì— 1ì„ ë”í•œ ê°’ì…ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;1ì€ safety marginì´ë¼ê³  í•´ì„œ, &lt;strong&gt;ì˜¤ë‹µì˜ scoreê°€ ì •ë‹µì˜ scoreë³´ë‹¤ 1 ì´ìƒ ì°¨ì´ë‚˜ëŠ” ì •ë„&lt;/strong&gt;ì— í•œí•´ Lossë¡œ ë°˜ì˜í•˜ê² ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ì•„ë˜ ì˜ˆì‹œë¥¼ í†µí•´ ì´í•´í•´ ë´…ì‹œë‹¤!
&lt;img src=&quot;../../assets/built/images/lec3_img_5.png&quot; alt=&quot;img_5.png&quot; /&gt;
ì •ë‹µ ë¼ë²¨(ê³ ì–‘ì´) ì„ ì œì™¸í•œ ëª¨ë“  class scoreë¥¼ labelì— í•´ë‹¹í•˜ëŠ” scoreì™€ì˜ ì—°ì‚°ì„ í†µí•´ 2.9 ë¼ëŠ” Loss ë¥¼ ë„ì¶œí•´ ë‚¸ ê²°ê³¼ë„¤ìš”.
ì´ëŸ¬í•œ ì—°ì‚°ì„ dataì˜ ê°œìˆ˜ë§Œí¼ ì‹¤í–‰ í›„ í‰ê· ì„ ë‚´ë©´ ìµœì¢…ì ìœ¼ë¡œ ìš°ë¦¬ê°€ ì›í•˜ëŠ” Lossê°’ì„ ì•Œ ìˆ˜ ìˆê²Œ ë¼ìš”!
&lt;img src=&quot;../../assets/built/images/lec3_img_6.png&quot; alt=&quot;img_6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì´ë¡œì„œ Lossê°€ 0ì´ ë˜ë„ë¡ parameterê°€ ì–¼ë§ˆë‚˜ ì•ˆì¢‹ì€ì§€ ê·¸ ì •ë„ë¥¼ ì•Œê³ , ë” ì¢‹ê²Œ ë§Œë“¤ ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;hinge-loss-ê´€ë ¨-ì§ˆë¬¸&quot;&gt;Hinge loss ê´€ë ¨ ì§ˆë¬¸&lt;/h3&gt;
&lt;p&gt;ì•„ë˜ì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ í™•ì¸í•´ë©´ì„œ ìˆ˜ì‹ì„ ì´í•´í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q1. What happens to the loss if car scores change a bit?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ NO CHANGE&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q2.Min/Max of loss&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ min = 0, Max = infinity&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q3. At initialization, W is small so all s~0. What is the loss?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ n-1 because (n-1) * 1&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q4. What if the sum was over all classes including $s_{y_i}$?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;â†’ Loss increases by 1&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q5. What if we used mean instead of sum ?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ Doesnâ€™t Change. We donâ€™t care the true values of the score&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q6. What if we used $max()^2$?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ Squared hinge loss. does not used normally&lt;/p&gt;

&lt;p&gt;SVM Loss ì•„ë˜ì™€ ê°™ì´ ê²½ì²©ê³¼ ê°™ì€ ëª¨ì–‘ì„ í•˜ê³  ìˆë‹¤ê³  í•´ì„œ hinge loss ë¼ê³  ë¶ˆë¦¬ê¸°ë„ í•©ë‹ˆë‹¤!
&lt;img src=&quot;../../assets/built/images/lec3_img_4.png&quot; alt=&quot;img_4.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;regularization&quot;&gt;Regularization&lt;/h3&gt;
&lt;p&gt;Regularizationì€ â€˜ì •ê·œí™”â€™ë¼ê³  í•´ì„ë˜ê¸°ë„ í•˜ë‚˜, ê°œì¸ì ìœ¼ë¡œ í•œê¸€ ìš©ì–´ë¡œ ì‚¬ìš©ì„ ì¶”ì²œë“œë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤.
Normalizationë„ ë˜‘ê°™ì´ â€˜ì •ê·œí™”â€™ ë¼ê³  í•´ì„ëœ ì±…ë“¤ì´ ë§ê¸° ë•Œë¬¸ì´ê³ , ë‘ ìš©ì–´ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ì˜ë¯¸ë¥¼ ê°–ê³  ìˆê¸° ë•Œë¬¸ì— í˜¼ë™ì„ ì•¼ê¸°í•  ê°€ëŠ¥ì„±ì´ ë‹¤ë¶„í•´ìš”.
ê·¸ë˜ì„œ ì´ ìš©ì–´ëŠ” ì˜ë¬¸ ë‹¨ì–´ ê·¸ìì²´ë¡œ ì˜ë¯¸ë¥¼ ë°›ì•„ë“¤ì´ê¸°ë¡œ í•˜ê³  ë“¤ì–´ê°€ ë´…ì‹œë‹¤.
&lt;img src=&quot;../../assets/built/images/lec3_img_7.png&quot; alt=&quot;img_7.png&quot; /&gt;
ê°•ì˜ì—ì„œ ì„¤ëª…í•˜ëŠ” ë‚´ìš©ì„ ê°„ë‹¨íˆ ìš”ì•½í•˜ìë©´, Overfittingì„ ë§‰ê¸° ìœ„í•´ì„œ, ì¦‰ â€˜ëª¨ë¸ì˜ ìœµí†µì„±ì„ ê¸°ë¥´ê¸° ìœ„í•´ì„œâ€™ ì¶”ê°€ë¡œ Loss functionì— ë”í•´ì£¼ëŠ” ì‘ì—…ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
ì´ ìš”ì†Œë¥¼ ë”í•´ì£¼ì§€ ì•Šìœ¼ë©´, Lossë¥¼ ìµœëŒ€í•œ ì¤„ì´ë„ë¡ parameterë¥¼ ì„¤ì •í•˜ê²Œ ë˜ì—ˆë”ë¼ë„ ê²°êµ­ ìƒˆë¡œìš´ test dataì—ëŠ” ë‚®ì€ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ë³´ì´ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.
ë‹¤ì‹œ ë§í•´, Loss functionì„ ë‹¨ìˆœíˆ ì¤„ì´ëŠ” ê²ƒë§Œì´ ëŠ¥ì‚¬ëŠ” ì•„ë‹ˆë¼ëŠ” ê²ƒì´ì§€ìš”.&lt;/p&gt;

&lt;p&gt;ì—¬ê¸°ì„œ $\lambda$ëŠ” ìš°ë¦¬ê°€ ì„¤ì •í•´ì£¼ì–´ì•¼ í•  hyperparameterì´ë©°, $R(W)$ ìš°ë¦¬ê°€ ë”í•´ì§€ëŠ” ê°’ì— ì ìš©í•  í˜ë„í‹°ì—ìš”.
ë³¸ ê°•ì˜ì—ì„œëŠ” L2 Regularizationì„ ì†Œê°œí•˜ë©´ì„œ weight ì›ì†Œë“¤ì˜ ì œê³±ê°’ì„ $R(W)$ ë¡œ ì •ì˜í•´ì„œ Loss functionì— í˜ë„í‹°ë¥¼ ì£¼ì—ˆì–´ìš”.
í˜ë„í‹°ë¥¼ ì£¼ì—ˆë‹¤ëŠ” ì–˜ê¸°ëŠ”, $R(W)$ ì˜ í¬ê¸°ê°€ í´ìˆ˜ë¡ ëª¨ë¸ì˜ ë³µì¡ë„ë¥¼ ë‚®ì¶”ëŠ” ë°©í–¥ìœ¼ë¡œ updateí•˜ë„ë¡ í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•˜ëŠ” ê±°ì—ìš”.&lt;br /&gt;
&lt;a href=&quot;https://www.notion.so/Lecture-3-Loss-functions-and-Optimization-3c46c15413324bc7856387118e6cfff1#f4708d3b84444fb7be5d93b71805083b&quot;&gt;L1, L2 Regularization&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Regularizationì—ëŠ” L1, L2 regularization ë§ê³ ë„ &lt;strong&gt;Dropout, Batch Normaization&lt;/strong&gt; ë“± ë§¤ìš° ìì£¼ ì“°ì´ë©° ì¤‘ìš”í•˜ê²Œ ë‹¤ë£¨ì–´ì§€ëŠ” ë°©ë²•ë“¤ì´ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì˜¤ëŠ˜ ë‚´ìš©ì´ ì¡°ê¸ˆ ì–´ë µë‹¤ë©´ ê´œì°®ìŠµë‹ˆë‹¤. ë‹¤ìŒì— ë˜ ë‹¤ì‹œ ë³´ë©´ì„œ Regularizationì— ëŒ€í•œ ì§ê´€ì„ ì–»ê³ ,
ì˜¤ëŠ˜ì€ &lt;strong&gt;Overfittingì„ ë§‰ê¸° ìœ„í•œ ê³¼ì •&lt;/strong&gt;ëŠ” ì‚¬ì‹¤ë§Œ ìš°ì„ ì ìœ¼ë¡œ ê¸°ì–µí•˜ê³  ë„˜ì–´ê°‘ì‹œë‹¤!&lt;/p&gt;

&lt;h3 id=&quot;softmax-function&quot;&gt;Softmax function&lt;/h3&gt;
&lt;p&gt;scoreë¥¼ ê¸°ë°˜ìœ¼ë¡œ, logë¥¼ í¬í•¨í•œ íŠ¹ì •í•œ ì—°ì‚°ì„ ì§„í–‰í•˜ê³ , multiclassì— ëŒ€í•œ í™•ë¥ ê°’ì„ return ë°›ëŠ” ë˜ë‹¤ë¥¸ Loss functionì…ë‹ˆë‹¤.
ì´ëŠ” ì°¨í›„ ìµí˜€ì•¼ í•  cross-entropyì™€ë„ ì—°ê´€ë˜ì–´ ìˆëŠ” ë§¤ìš° ì¤‘ìš”í•œ ê°œë…ì´ë‹ˆ ì˜ ìµí˜€ë‘¡ì‹œë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/lec3_img_8.png&quot; alt=&quot;img_8.png&quot; /&gt;
ìœ„ ìŠ¬ë¼ì´ë“œì— êµ‰ì¥íˆ ë§ì€ ë‚´ìš©ì´ í•¨ì¶•ë˜ì–´ ìˆìœ¼ë‹ˆ ì£¼ì˜ê¹Šê²Œ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;optimization&quot;&gt;Optimization&lt;/h2&gt;
&lt;h3 id=&quot;stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/h3&gt;

&lt;h2 id=&quot;ì§ˆë¬¸&quot;&gt;ì§ˆë¬¸&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;softmax functionì—ì„œ logë¥¼ ì“°ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?&lt;/li&gt;
  &lt;li&gt;multiclass SVM Loss ëŠ” ì™œ SVM Lossë¼ëŠ” ì´ë¦„ì´ ë¶™ì—ˆì„ê¹Œìš”?&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>ê±´ë„ˆë³„(crosstar)</name>
        
        
      </author>

      

      
        <category term="ML" />
      

      
        <summary type="html">GOAL parameterë¥¼ Loss functionì„ í†µí•´ updateí•˜ëŠ” optimization ê³¼ì •ì„ ì´í•´í•©ë‹ˆë‹¤. Gradient descent ê³¼ì •ì„ ê°œê´„ì ìœ¼ë¡œ ì´í•´í•©ë‹ˆë‹¤.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">ë‚´ìš© í•µì‹¬ìš”ì•½! CS231n Lecture 4. Backpropagation</title>
      <link href="https://crosstar1228.github.io/cs231n-lec4" rel="alternate" type="text/html" title="ë‚´ìš© í•µì‹¬ìš”ì•½! CS231n Lecture 4.  Backpropagation" />
      <published>2021-10-14T11:00:00+00:00</published>
      <updated>2021-10-14T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/cs231n-lec4</id>
      <content type="html" xml:base="https://crosstar1228.github.io/cs231n-lec4">&lt;h1 id=&quot;goal&quot;&gt;GOAL&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;parameterë¥¼ Loss functionì„ í†µí•´ updateí•˜ëŠ” &lt;em&gt;optimization&lt;/em&gt; ê³¼ì •ì„ ì´í•´í•©ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;Gradient descent ê³¼ì •ì„ ê°œê´„ì ìœ¼ë¡œ ì´í•´í•©ë‹ˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#loss-function&quot;&gt;Loss function&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#multiclass-svm-loss&quot;&gt;Multiclass SVM Loss&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#regularization&quot;&gt;Regularization&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#Softmax-function&quot;&gt;Softmax function&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#optimization&quot;&gt;Optimization&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;loss-function&quot;&gt;Loss function&lt;/h2&gt;
&lt;p&gt;ì§€ë‚œ ì‹œê°„ì— ìš°ë¦¬ëŠ” Parameterë¥¼ update, ì¦‰ ìµœì ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì°¾ì•„ë‚´ëŠ” ë°©ë²•ì— ëŒ€í•œ í•„ìš”ì„±ì„ ëŠê¼ˆìŠµë‹ˆë‹¤.
í•œ ë§ˆë””ë¡œ ì´ë²ˆ ê°•ì˜ì—ì„œ ì„¤ëª…í•  ìµœì í™”(Optimization)ì— ëŒ€í•œ ì´ì•¼ê¸°ì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ë¥¼ ìœ„í•œ í•µì‹¬ ê°œë…ì¸ ì†ì‹¤ í•¨ìˆ˜(Loss function)ì— ëŒ€í•˜ì—¬ ìš°ì„ ì ìœ¼ë¡œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;what-is-loss-function&quot;&gt;What is loss function?&lt;/h3&gt;
&lt;p&gt;Loss function(ì†ì‹¤ í•¨ìˆ˜, ì´í•˜ í•œê¸€ ìš©ì–´ ìƒëµ)ì€ ë‹¤ë¥¸ ë§ë¡œ Cost functionì´ë¼ê³  í•©ë‹ˆë‹¤.
Loss ë˜ëŠ” costë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë‹¤! ì´ë ‡ê²Œ ì˜ˆìƒì´ ë˜ë„¤ìš”.
ê·¸ë¦¬ê³  ê·¸ëŸ¬í•œ ì†ì‹¤(ë˜ëŠ” ë¹„ìš©)ì´ ì¤„ì–´ë“œëŠ” ê²ƒì´ ë” ë°”ëŒì§í•œ ë°©í–¥ì´ë¼ëŠ” ê°ê¹Œì§€ ì˜¤ì…¨ë‹¤ë©´
Loss functionì— ëŒ€í•œ ì§ê´€ì€ ì´ë¯¸ ë°˜ ì •ë„ ìµíˆì‹  ê²ƒìœ¼ë¡œ ìƒê°ë˜ë„¤ìš”. ì¡°ê¸ˆë” ìì„¸íˆ ë“¤ì–´ë‹¤ ë³¼ê¹Œìš”?
&lt;img src=&quot;../../assets/built/images/lec3_img.png&quot; alt=&quot;img.png&quot; /&gt;
ìš°ë¦¬ëŠ” ìœ„ì™€ ê°™ì€ ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì§„ì§œ class(label ë˜ëŠ” ì •ë‹µ)ì— í•´ë‹¹í•˜ëŠ” scoreê°€ ê°€ì¥ ë†’ì€ ì ìˆ˜ê°€ ë‚˜ì˜¤ë„ë¡ ëª¨ë¸ì„ ë§Œë“¤ê³  ì‹¶ì–´ìš”.
ê·¸ë˜ì•¼ë§Œ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë„ ì˜¬ë°”ë¥¸ ì •ë‹µìœ¼ë¡œ íŒë‹¨í•  í™•ë¥ ì´ ë†’ì„ í…Œë‹ˆê¹Œìš”. ìš°ë¦¬ëŠ” ì´ê²ƒì€ ì •í™•ë„(accuracy) ë“±ì˜ ì§€í‘œë¡œ íŒë‹¨í•˜ê²Œ ë©ë‹ˆë‹¤.
í•˜ì§€ë§Œ ê·¸ë¦¼ì„ ë³´ë©´ ê³ ì–‘ì´ì˜ ì •ë‹µì„ ê°€ì§„ ì‚¬ì§„ì€ deer(ì‚¬ìŠ´)ì— í•´ë‹¹í•˜ëŠ” ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°–ê³  ìˆê³ , ê°œêµ¬ë¦¬ëŠ” truck(íŠ¸ëŸ­)ì— í•´ë‹¹í•˜ëŠ” ì ìˆ˜ë¥¼ ê°€ì¥ ë†’ê²Œ ê°–ê³  ìˆë„¤ìš”.&lt;/p&gt;

&lt;p&gt;ìˆ˜ì¹˜ë¡œ í‘œí˜„ëœ ì´ëŸ¬í•œ ì ìˆ˜(score)ë“¤ì´ ì–¼ë§ˆë‚˜ ë°”ëŒì§í•œì§€, &lt;strong&gt;ì •ëŸ‰ì ìœ¼ë¡œ&lt;/strong&gt; ì–´ê¸‹ë‚œ ì •ë„ë¥¼ íŒë‹¨í•  í•„ìš”ì„±ì„ ëŠë‚ë‹ˆë‹¤.
ê·¸ ë²—ì–´ë‚œ ì •ë„ë¥¼ ì•Œì•„ì•¼ ì•Œë§ê²Œ ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
ì •ëŸ‰ì ì¸ ìˆ˜ì¹˜ë¡œ í‘œí˜„í•´ì•¼ í•˜ë‹ˆ, íŠ¹ì •í•œ ì…ë ¥ê°’ë§ˆë‹¤ ë³€í•˜ëŠ” í•˜ë‚˜ì˜ í•¨ìˆ˜ê°€ ì •ì˜ë˜ëŠ” ê²ƒì´ê³ ,
ê·¸ê²ƒì´ Loss functionìœ¼ë¡œ í‘œí˜„ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
&lt;img src=&quot;../../assets/built/images/lec3_img_3.png&quot; alt=&quot;img_3.png&quot; /&gt;
&lt;img src=&quot;../../assets/built/images/lec3_img_1.png&quot; alt=&quot;img_1.png&quot; /&gt;
$f(x_i, W)$ : inputê³¼ parameterì— ì˜í•œ ì˜ˆì¸¡ëœ scoreë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.&lt;br /&gt;
$y_i$ : label, ì¦‰ ì •ë‹µì— í•´ë‹¹í•˜ëŠ” scoreë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ë¶„ë¥˜ ë¬¸ì œì—ì„œëŠ” ì •ë‹µì˜ classê°€ 1, ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ ê¸°ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë‘ ê°’ì˜ ì°¨ì´ê°€ Nê°œì˜ dataë³„ë¡œ ê°ê° ì¡´ì¬í•  ê²ƒì´ê³ , ê·¸ê²ƒì„ í‰ê· ë‚¸ ê°’ì„ ìš°ë¦¬ëŠ” $L(W)$ë¡œ ì •ì˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 
$W$, ì¦‰ parameterê°€ ë…ë¦½ë³€ìˆ˜ë¡œ ì¡´ì¬í•˜ëŠ” í•¨ìˆ˜ì´ë‹ˆ, ì´ ê°’ì— ë”°ë¼ Loss functionì˜ ê²°ê´ê°’ë„ ë‹¬ë¼ì§€ì§€ë¼ëŠ” ê²ƒì„ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ëŸ¬í•œ Loss functionì˜ ì˜ˆì‹œì¸ Multiclass SVM Loss ë¥¼ ì‚´í´ë³´ë©° ì´í•´ë„ë¥¼ ë†’ì—¬ ë³´ê² ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;multiclass-svm-loss&quot;&gt;Multiclass SVM Loss&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/lec3_img_2.png&quot; alt=&quot;img_2.png&quot; /&gt;
 ì´ì „ì— í¸ì˜ìƒ scoreë¼ê³  í‘œí˜„í•œ ì˜ˆì¸¡ê°’ì´ ì—¬ê¸°ì„œ ì •ì‹ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤.
ê·¸ë¦¬ê³  $L_i$ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ë¼ìš”!&lt;/p&gt;

&lt;p&gt;$L_i = \underset{j\not=y_i} \sum$
\(\begin{cases}0 \qquad\qquad\qquad if\quad s_{y_i}\geq s_j + 1\\s_j - s_{y_i} + 1\quad \: if\quad otherwise
\end{cases}\)&lt;/p&gt;

&lt;p&gt;ë‹¤ì‹œ ì“°ìë©´,&lt;/p&gt;

&lt;p&gt;$L_i = \underset{j\not=y_i} \sum max(0, s_j - s_{y_i} + 1 )$&lt;/p&gt;

&lt;p&gt;$s_j$ : jë²ˆì§¸ class score&lt;br /&gt;
$s_{y_i}$ : ì •ë‹µ(label)ì— í•´ë‹¹í•˜ëŠ” score&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;ì–´ë–¤ ìˆ˜ì‹ì„ ì´í•´í•˜ëŠ”ë° ìµœìš°ì„ ì¸ ì§ê´€ë¶€í„° ê°€ì ¸ê°€ ë´…ì‹œë‹¤.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;0ê³¼ &lt;strong&gt;íŠ¹ì •í•œ ê°’&lt;/strong&gt;ì¤‘ì—ì„œ ìµœëŒ€ë¥¼ ê³¨ë¼ìš”. ê·¸ íŠ¹ì •í•œ ê°’ì´ë¼ëŠ” ê²ƒì€&lt;/li&gt;
  &lt;li&gt;(jë²ˆì§¸ class score) - (ì •ë‹µì— í•´ë‹¹í•˜ëŠ” class score) ë¥¼ êµ¬í•˜ê³  ê·¸ê²ƒì— 1ì„ ë”í•œ ê°’ì…ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;1ì€ safety marginì´ë¼ê³  í•´ì„œ, &lt;strong&gt;ì˜¤ë‹µì˜ scoreê°€ ì •ë‹µì˜ scoreë³´ë‹¤ 1 ì´ìƒ ì°¨ì´ë‚˜ëŠ” ì •ë„&lt;/strong&gt;ì— í•œí•´ Lossë¡œ ë°˜ì˜í•˜ê² ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ì•„ë˜ ì˜ˆì‹œë¥¼ í†µí•´ ì´í•´í•´ ë´…ì‹œë‹¤!
&lt;img src=&quot;../../assets/built/images/lec3_img_5.png&quot; alt=&quot;img_5.png&quot; /&gt;
ì •ë‹µ ë¼ë²¨(ê³ ì–‘ì´) ì„ ì œì™¸í•œ ëª¨ë“  class scoreë¥¼ labelì— í•´ë‹¹í•˜ëŠ” scoreì™€ì˜ ì—°ì‚°ì„ í†µí•´ 2.9 ë¼ëŠ” Loss ë¥¼ ë„ì¶œí•´ ë‚¸ ê²°ê³¼ë„¤ìš”.
ì´ëŸ¬í•œ ì—°ì‚°ì„ dataì˜ ê°œìˆ˜ë§Œí¼ ì‹¤í–‰ í›„ í‰ê· ì„ ë‚´ë©´ ìµœì¢…ì ìœ¼ë¡œ ìš°ë¦¬ê°€ ì›í•˜ëŠ” Lossê°’ì„ ì•Œ ìˆ˜ ìˆê²Œ ë¼ìš”!
&lt;img src=&quot;../../assets/built/images/lec3_img_6.png&quot; alt=&quot;img_6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì´ë¡œì„œ Lossê°€ 0ì´ ë˜ë„ë¡ parameterê°€ ì–¼ë§ˆë‚˜ ì•ˆì¢‹ì€ì§€ ê·¸ ì •ë„ë¥¼ ì•Œê³ , ë” ì¢‹ê²Œ ë§Œë“¤ ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;hinge-loss-ê´€ë ¨-ì§ˆë¬¸&quot;&gt;Hinge loss ê´€ë ¨ ì§ˆë¬¸&lt;/h3&gt;
&lt;p&gt;ì•„ë˜ì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ í™•ì¸í•´ë©´ì„œ ìˆ˜ì‹ì„ ì´í•´í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q1. What happens to the loss if car scores change a bit?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ NO CHANGE&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q2.Min/Max of loss&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ min = 0, Max = infinity&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q3. At initialization, W is small so all s~0. What is the loss?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ n-1 because (n-1) * 1&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q4. What if the sum was over all classes including $s_{y_i}$?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;â†’ Loss increases by 1&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q5. What if we used mean instead of sum ?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ Doesnâ€™t Change. We donâ€™t care the true values of the score&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q6. What if we used $max()^2$?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ Squared hinge loss. does not used normally&lt;/p&gt;

&lt;p&gt;SVM Loss ì•„ë˜ì™€ ê°™ì´ ê²½ì²©ê³¼ ê°™ì€ ëª¨ì–‘ì„ í•˜ê³  ìˆë‹¤ê³  í•´ì„œ hinge loss ë¼ê³  ë¶ˆë¦¬ê¸°ë„ í•©ë‹ˆë‹¤!
&lt;img src=&quot;../../assets/built/images/lec3_img_4.png&quot; alt=&quot;img_4.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;regularization&quot;&gt;Regularization&lt;/h3&gt;
&lt;p&gt;Regularizationì€ â€˜ì •ê·œí™”â€™ë¼ê³  í•´ì„ë˜ê¸°ë„ í•˜ë‚˜, ê°œì¸ì ìœ¼ë¡œ í•œê¸€ ìš©ì–´ë¡œ ì‚¬ìš©ì„ ì¶”ì²œë“œë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤.
Normalizationë„ ë˜‘ê°™ì´ â€˜ì •ê·œí™”â€™ ë¼ê³  í•´ì„ëœ ì±…ë“¤ì´ ë§ê¸° ë•Œë¬¸ì´ê³ , ë‘ ìš©ì–´ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ì˜ë¯¸ë¥¼ ê°–ê³  ìˆê¸° ë•Œë¬¸ì— í˜¼ë™ì„ ì•¼ê¸°í•  ê°€ëŠ¥ì„±ì´ ë‹¤ë¶„í•´ìš”.
ê·¸ë˜ì„œ ì´ ìš©ì–´ëŠ” ì˜ë¬¸ ë‹¨ì–´ ê·¸ìì²´ë¡œ ì˜ë¯¸ë¥¼ ë°›ì•„ë“¤ì´ê¸°ë¡œ í•˜ê³  ë“¤ì–´ê°€ ë´…ì‹œë‹¤.
&lt;img src=&quot;../../assets/built/images/lec3_img_7.png&quot; alt=&quot;img_7.png&quot; /&gt;
ê°•ì˜ì—ì„œ ì„¤ëª…í•˜ëŠ” ë‚´ìš©ì„ ê°„ë‹¨íˆ ìš”ì•½í•˜ìë©´, Overfittingì„ ë§‰ê¸° ìœ„í•´ì„œ, ì¦‰ â€˜ëª¨ë¸ì˜ ìœµí†µì„±ì„ ê¸°ë¥´ê¸° ìœ„í•´ì„œâ€™ ì¶”ê°€ë¡œ Loss functionì— ë”í•´ì£¼ëŠ” ì‘ì—…ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
ì´ ìš”ì†Œë¥¼ ë”í•´ì£¼ì§€ ì•Šìœ¼ë©´, Lossë¥¼ ìµœëŒ€í•œ ì¤„ì´ë„ë¡ parameterë¥¼ ì„¤ì •í•˜ê²Œ ë˜ì—ˆë”ë¼ë„ ê²°êµ­ ìƒˆë¡œìš´ test dataì—ëŠ” ë‚®ì€ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ë³´ì´ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.
ë‹¤ì‹œ ë§í•´, Loss functionì„ ë‹¨ìˆœíˆ ì¤„ì´ëŠ” ê²ƒë§Œì´ ëŠ¥ì‚¬ëŠ” ì•„ë‹ˆë¼ëŠ” ê²ƒì´ì§€ìš”.&lt;/p&gt;

&lt;p&gt;ì—¬ê¸°ì„œ $\lambda$ëŠ” ìš°ë¦¬ê°€ ì„¤ì •í•´ì£¼ì–´ì•¼ í•  hyperparameterì´ë©°, $R(W)$ ìš°ë¦¬ê°€ ë”í•´ì§€ëŠ” ê°’ì— ì ìš©í•  í˜ë„í‹°ì—ìš”.
ë³¸ ê°•ì˜ì—ì„œëŠ” L2 Regularizationì„ ì†Œê°œí•˜ë©´ì„œ weight ì›ì†Œë“¤ì˜ ì œê³±ê°’ì„ $R(W)$ ë¡œ ì •ì˜í•´ì„œ Loss functionì— í˜ë„í‹°ë¥¼ ì£¼ì—ˆì–´ìš”.
í˜ë„í‹°ë¥¼ ì£¼ì—ˆë‹¤ëŠ” ì–˜ê¸°ëŠ”, $R(W)$ ì˜ í¬ê¸°ê°€ í´ìˆ˜ë¡ ëª¨ë¸ì˜ ë³µì¡ë„ë¥¼ ë‚®ì¶”ëŠ” ë°©í–¥ìœ¼ë¡œ updateí•˜ë„ë¡ í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•˜ëŠ” ê±°ì—ìš”.&lt;br /&gt;
&lt;a href=&quot;https://www.notion.so/Lecture-3-Loss-functions-and-Optimization-3c46c15413324bc7856387118e6cfff1#f4708d3b84444fb7be5d93b71805083b&quot;&gt;L1, L2 Regularization&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Regularizationì—ëŠ” L1, L2 regularization ë§ê³ ë„ &lt;strong&gt;Dropout, Batch Normaization&lt;/strong&gt; ë“± ë§¤ìš° ìì£¼ ì“°ì´ë©° ì¤‘ìš”í•˜ê²Œ ë‹¤ë£¨ì–´ì§€ëŠ” ë°©ë²•ë“¤ì´ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì˜¤ëŠ˜ ë‚´ìš©ì´ ì¡°ê¸ˆ ì–´ë µë‹¤ë©´ ê´œì°®ìŠµë‹ˆë‹¤. ë‹¤ìŒì— ë˜ ë‹¤ì‹œ ë³´ë©´ì„œ Regularizationì— ëŒ€í•œ ì§ê´€ì„ ì–»ê³ ,
ì˜¤ëŠ˜ì€ &lt;strong&gt;Overfittingì„ ë§‰ê¸° ìœ„í•œ ê³¼ì •&lt;/strong&gt;ëŠ” ì‚¬ì‹¤ë§Œ ìš°ì„ ì ìœ¼ë¡œ ê¸°ì–µí•˜ê³  ë„˜ì–´ê°‘ì‹œë‹¤!&lt;/p&gt;

&lt;h3 id=&quot;softmax-function&quot;&gt;Softmax function&lt;/h3&gt;
&lt;p&gt;scoreë¥¼ ê¸°ë°˜ìœ¼ë¡œ, logë¥¼ í¬í•¨í•œ íŠ¹ì •í•œ ì—°ì‚°ì„ ì§„í–‰í•˜ê³ , multiclassì— ëŒ€í•œ í™•ë¥ ê°’ì„ return ë°›ëŠ” ë˜ë‹¤ë¥¸ Loss functionì…ë‹ˆë‹¤.
ì´ëŠ” ì°¨í›„ ìµí˜€ì•¼ í•  cross-entropyì™€ë„ ì—°ê´€ë˜ì–´ ìˆëŠ” ë§¤ìš° ì¤‘ìš”í•œ ê°œë…ì´ë‹ˆ ì˜ ìµí˜€ë‘¡ì‹œë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/lec3_img_8.png&quot; alt=&quot;img_8.png&quot; /&gt;
ìœ„ ìŠ¬ë¼ì´ë“œì— êµ‰ì¥íˆ ë§ì€ ë‚´ìš©ì´ í•¨ì¶•ë˜ì–´ ìˆìœ¼ë‹ˆ ì£¼ì˜ê¹Šê²Œ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;optimization&quot;&gt;Optimization&lt;/h2&gt;
&lt;h3 id=&quot;stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/h3&gt;

&lt;h2 id=&quot;ì§ˆë¬¸&quot;&gt;ì§ˆë¬¸&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;softmax functionì—ì„œ logë¥¼ ì“°ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?&lt;/li&gt;
  &lt;li&gt;multiclass SVM Loss ëŠ” ì™œ SVM Lossë¼ëŠ” ì´ë¦„ì´ ë¶™ì—ˆì„ê¹Œìš”?&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>ê±´ë„ˆë³„(crosstar)</name>
        
        
      </author>

      

      
        <category term="ML" />
      

      
        <summary type="html">GOAL parameterë¥¼ Loss functionì„ í†µí•´ updateí•˜ëŠ” optimization ê³¼ì •ì„ ì´í•´í•©ë‹ˆë‹¤. Gradient descent ê³¼ì •ì„ ê°œê´„ì ìœ¼ë¡œ ì´í•´í•©ë‹ˆë‹¤.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">ë‚´ìš© í•µì‹¬ìš”ì•½! CS231n Lecture 3. Loss function and Optimization</title>
      <link href="https://crosstar1228.github.io/cs231n-lec3" rel="alternate" type="text/html" title="ë‚´ìš© í•µì‹¬ìš”ì•½! CS231n Lecture 3.  Loss function and Optimization" />
      <published>2021-10-14T11:00:00+00:00</published>
      <updated>2021-10-14T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/cs231n-lec3</id>
      <content type="html" xml:base="https://crosstar1228.github.io/cs231n-lec3">&lt;h1 id=&quot;goal&quot;&gt;GOAL&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;parameterë¥¼ Loss functionì„ í†µí•´ updateí•˜ëŠ” &lt;em&gt;optimization&lt;/em&gt; ê³¼ì •ì„ ì´í•´í•©ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;Gradient descent ê³¼ì •ì„ ê°œê´„ì ìœ¼ë¡œ ì´í•´í•©ë‹ˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#loss-function&quot;&gt;Loss function&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#multiclass-svm-loss&quot;&gt;Multiclass SVM Loss&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#regularization&quot;&gt;Regularization&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#Softmax-function&quot;&gt;Softmax function&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#optimization&quot;&gt;Optimization&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;loss-function&quot;&gt;Loss function&lt;/h2&gt;
&lt;p&gt;ì§€ë‚œ ì‹œê°„ì— ìš°ë¦¬ëŠ” Parameterë¥¼ update, ì¦‰ ìµœì ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì°¾ì•„ë‚´ëŠ” ë°©ë²•ì— ëŒ€í•œ í•„ìš”ì„±ì„ ëŠê¼ˆìŠµë‹ˆë‹¤.
í•œ ë§ˆë””ë¡œ ì´ë²ˆ ê°•ì˜ì—ì„œ ì„¤ëª…í•  ìµœì í™”(Optimization)ì— ëŒ€í•œ ì´ì•¼ê¸°ì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ë¥¼ ìœ„í•œ í•µì‹¬ ê°œë…ì¸ ì†ì‹¤ í•¨ìˆ˜(Loss function)ì— ëŒ€í•˜ì—¬ ìš°ì„ ì ìœ¼ë¡œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;what-is-loss-function&quot;&gt;What is loss function?&lt;/h3&gt;
&lt;p&gt;Loss function(ì†ì‹¤ í•¨ìˆ˜, ì´í•˜ í•œê¸€ ìš©ì–´ ìƒëµ)ì€ ë‹¤ë¥¸ ë§ë¡œ Cost functionì´ë¼ê³  í•©ë‹ˆë‹¤.
Loss ë˜ëŠ” costë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë‹¤! ì´ë ‡ê²Œ ì˜ˆìƒì´ ë˜ë„¤ìš”.
ê·¸ë¦¬ê³  ê·¸ëŸ¬í•œ ì†ì‹¤(ë˜ëŠ” ë¹„ìš©)ì´ ì¤„ì–´ë“œëŠ” ê²ƒì´ ë” ë°”ëŒì§í•œ ë°©í–¥ì´ë¼ëŠ” ê°ê¹Œì§€ ì˜¤ì…¨ë‹¤ë©´
Loss functionì— ëŒ€í•œ ì§ê´€ì€ ì´ë¯¸ ë°˜ ì •ë„ ìµíˆì‹  ê²ƒìœ¼ë¡œ ìƒê°ë˜ë„¤ìš”. ì¡°ê¸ˆë” ìì„¸íˆ ë“¤ì–´ë‹¤ ë³¼ê¹Œìš”?
&lt;img src=&quot;../../assets/built/images/lec3_img.png&quot; alt=&quot;img.png&quot; /&gt;
ìš°ë¦¬ëŠ” ìœ„ì™€ ê°™ì€ ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì§„ì§œ class(label ë˜ëŠ” ì •ë‹µ)ì— í•´ë‹¹í•˜ëŠ” scoreê°€ ê°€ì¥ ë†’ì€ ì ìˆ˜ê°€ ë‚˜ì˜¤ë„ë¡ ëª¨ë¸ì„ ë§Œë“¤ê³  ì‹¶ì–´ìš”.
ê·¸ë˜ì•¼ë§Œ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë„ ì˜¬ë°”ë¥¸ ì •ë‹µìœ¼ë¡œ íŒë‹¨í•  í™•ë¥ ì´ ë†’ì„ í…Œë‹ˆê¹Œìš”. ìš°ë¦¬ëŠ” ì´ê²ƒì€ ì •í™•ë„(accuracy) ë“±ì˜ ì§€í‘œë¡œ íŒë‹¨í•˜ê²Œ ë©ë‹ˆë‹¤.
í•˜ì§€ë§Œ ê·¸ë¦¼ì„ ë³´ë©´ ê³ ì–‘ì´ì˜ ì •ë‹µì„ ê°€ì§„ ì‚¬ì§„ì€ deer(ì‚¬ìŠ´)ì— í•´ë‹¹í•˜ëŠ” ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°–ê³  ìˆê³ , ê°œêµ¬ë¦¬ëŠ” truck(íŠ¸ëŸ­)ì— í•´ë‹¹í•˜ëŠ” ì ìˆ˜ë¥¼ ê°€ì¥ ë†’ê²Œ ê°–ê³  ìˆë„¤ìš”.&lt;/p&gt;

&lt;p&gt;ìˆ˜ì¹˜ë¡œ í‘œí˜„ëœ ì´ëŸ¬í•œ ì ìˆ˜(score)ë“¤ì´ ì–¼ë§ˆë‚˜ ë°”ëŒì§í•œì§€, &lt;strong&gt;ì •ëŸ‰ì ìœ¼ë¡œ&lt;/strong&gt; ì–´ê¸‹ë‚œ ì •ë„ë¥¼ íŒë‹¨í•  í•„ìš”ì„±ì„ ëŠë‚ë‹ˆë‹¤.
ê·¸ ë²—ì–´ë‚œ ì •ë„ë¥¼ ì•Œì•„ì•¼ ì•Œë§ê²Œ ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
ì •ëŸ‰ì ì¸ ìˆ˜ì¹˜ë¡œ í‘œí˜„í•´ì•¼ í•˜ë‹ˆ, íŠ¹ì •í•œ ì…ë ¥ê°’ë§ˆë‹¤ ë³€í•˜ëŠ” í•˜ë‚˜ì˜ í•¨ìˆ˜ê°€ ì •ì˜ë˜ëŠ” ê²ƒì´ê³ ,
ê·¸ê²ƒì´ Loss functionìœ¼ë¡œ í‘œí˜„ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
&lt;img src=&quot;../../assets/built/images/lec3_img_3.png&quot; alt=&quot;img_3.png&quot; /&gt;
&lt;img src=&quot;../../assets/built/images/lec3_img_1.png&quot; alt=&quot;img_1.png&quot; /&gt;
$f(x_i, W)$ : inputê³¼ parameterì— ì˜í•œ ì˜ˆì¸¡ëœ scoreë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.&lt;br /&gt;
$y_i$ : label, ì¦‰ ì •ë‹µì— í•´ë‹¹í•˜ëŠ” scoreë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ë¶„ë¥˜ ë¬¸ì œì—ì„œëŠ” ì •ë‹µì˜ classê°€ 1, ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ ê¸°ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë‘ ê°’ì˜ ì°¨ì´ê°€ Nê°œì˜ dataë³„ë¡œ ê°ê° ì¡´ì¬í•  ê²ƒì´ê³ , ê·¸ê²ƒì„ í‰ê· ë‚¸ ê°’ì„ ìš°ë¦¬ëŠ” $L(W)$ë¡œ ì •ì˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 
$W$, ì¦‰ parameterê°€ ë…ë¦½ë³€ìˆ˜ë¡œ ì¡´ì¬í•˜ëŠ” í•¨ìˆ˜ì´ë‹ˆ, ì´ ê°’ì— ë”°ë¼ Loss functionì˜ ê²°ê´ê°’ë„ ë‹¬ë¼ì§€ì§€ë¼ëŠ” ê²ƒì„ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ëŸ¬í•œ Loss functionì˜ ì˜ˆì‹œì¸ Multiclass SVM Loss ë¥¼ ì‚´í´ë³´ë©° ì´í•´ë„ë¥¼ ë†’ì—¬ ë³´ê² ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;multiclass-svm-loss&quot;&gt;Multiclass SVM Loss&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/lec3_img_2.png&quot; alt=&quot;img_2.png&quot; /&gt;
 ì´ì „ì— í¸ì˜ìƒ scoreë¼ê³  í‘œí˜„í•œ ì˜ˆì¸¡ê°’ì´ ì—¬ê¸°ì„œ ì •ì‹ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤.
ê·¸ë¦¬ê³  $L_i$ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ë¼ìš”!&lt;/p&gt;

&lt;p&gt;$L_i = \underset{j\not=y_i} \sum$
\(\begin{cases}0 \qquad\qquad\qquad if\quad s_{y_i}\geq s_j + 1\\s_j - s_{y_i} + 1\quad \: if\quad otherwise
\end{cases}\)&lt;/p&gt;

&lt;p&gt;ë‹¤ì‹œ ì“°ìë©´,&lt;/p&gt;

&lt;p&gt;$L_i = \underset{j\not=y_i} \sum max(0, s_j - s_{y_i} + 1 )$&lt;/p&gt;

&lt;p&gt;$s_j$ : jë²ˆì§¸ class score&lt;br /&gt;
$s_{y_i}$ : ì •ë‹µ(label)ì— í•´ë‹¹í•˜ëŠ” score&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;ì–´ë–¤ ìˆ˜ì‹ì„ ì´í•´í•˜ëŠ”ë° ìµœìš°ì„ ì¸ ì§ê´€ë¶€í„° ê°€ì ¸ê°€ ë´…ì‹œë‹¤.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;0ê³¼ &lt;strong&gt;íŠ¹ì •í•œ ê°’&lt;/strong&gt;ì¤‘ì—ì„œ ìµœëŒ€ë¥¼ ê³¨ë¼ìš”. ê·¸ íŠ¹ì •í•œ ê°’ì´ë¼ëŠ” ê²ƒì€&lt;/li&gt;
  &lt;li&gt;(jë²ˆì§¸ class score) - (ì •ë‹µì— í•´ë‹¹í•˜ëŠ” class score) ë¥¼ êµ¬í•˜ê³  ê·¸ê²ƒì— 1ì„ ë”í•œ ê°’ì…ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;1ì€ safety marginì´ë¼ê³  í•´ì„œ, &lt;strong&gt;ì˜¤ë‹µì˜ scoreê°€ ì •ë‹µì˜ scoreë³´ë‹¤ 1 ì´ìƒ ì°¨ì´ë‚˜ëŠ” ì •ë„&lt;/strong&gt;ì— í•œí•´ Lossë¡œ ë°˜ì˜í•˜ê² ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ì•„ë˜ ì˜ˆì‹œë¥¼ í†µí•´ ì´í•´í•´ ë´…ì‹œë‹¤!
&lt;img src=&quot;../../assets/built/images/lec3_img_5.png&quot; alt=&quot;img_5.png&quot; /&gt;
ì •ë‹µ ë¼ë²¨(ê³ ì–‘ì´) ì„ ì œì™¸í•œ ëª¨ë“  class scoreë¥¼ labelì— í•´ë‹¹í•˜ëŠ” scoreì™€ì˜ ì—°ì‚°ì„ í†µí•´ 2.9 ë¼ëŠ” Loss ë¥¼ ë„ì¶œí•´ ë‚¸ ê²°ê³¼ë„¤ìš”.
ì´ëŸ¬í•œ ì—°ì‚°ì„ dataì˜ ê°œìˆ˜ë§Œí¼ ì‹¤í–‰ í›„ í‰ê· ì„ ë‚´ë©´ ìµœì¢…ì ìœ¼ë¡œ ìš°ë¦¬ê°€ ì›í•˜ëŠ” Lossê°’ì„ ì•Œ ìˆ˜ ìˆê²Œ ë¼ìš”!
&lt;img src=&quot;../../assets/built/images/lec3_img_6.png&quot; alt=&quot;img_6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì´ë¡œì„œ Lossê°€ 0ì´ ë˜ë„ë¡ parameterê°€ ì–¼ë§ˆë‚˜ ì•ˆì¢‹ì€ì§€ ê·¸ ì •ë„ë¥¼ ì•Œê³ , ë” ì¢‹ê²Œ ë§Œë“¤ ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;hinge-loss-ê´€ë ¨-ì§ˆë¬¸&quot;&gt;Hinge loss ê´€ë ¨ ì§ˆë¬¸&lt;/h3&gt;
&lt;p&gt;ì•„ë˜ì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ í™•ì¸í•´ë©´ì„œ ìˆ˜ì‹ì„ ì´í•´í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q1. What happens to the loss if car scores change a bit?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ NO CHANGE&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q2.Min/Max of loss&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ min = 0, Max = infinity&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q3. At initialization, W is small so all s~0. What is the loss?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ n-1 because (n-1) * 1&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q4. What if the sum was over all classes including $s_{y_i}$?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;â†’ Loss increases by 1&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q5. What if we used mean instead of sum ?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ Doesnâ€™t Change. We donâ€™t care the true values of the score&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q6. What if we used $max()^2$?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;â†’ Squared hinge loss. does not used normally&lt;/p&gt;

&lt;p&gt;SVM Loss ì•„ë˜ì™€ ê°™ì´ ê²½ì²©ê³¼ ê°™ì€ ëª¨ì–‘ì„ í•˜ê³  ìˆë‹¤ê³  í•´ì„œ hinge loss ë¼ê³  ë¶ˆë¦¬ê¸°ë„ í•©ë‹ˆë‹¤!
&lt;img src=&quot;../../assets/built/images/lec3_img_4.png&quot; alt=&quot;img_4.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;regularization&quot;&gt;Regularization&lt;/h3&gt;
&lt;p&gt;Regularizationì€ â€˜ì •ê·œí™”â€™ë¼ê³  í•´ì„ë˜ê¸°ë„ í•˜ë‚˜, ê°œì¸ì ìœ¼ë¡œ í•œê¸€ ìš©ì–´ë¡œ ì‚¬ìš©ì„ ì¶”ì²œë“œë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤.
Normalizationë„ ë˜‘ê°™ì´ â€˜ì •ê·œí™”â€™ ë¼ê³  í•´ì„ëœ ì±…ë“¤ì´ ë§ê¸° ë•Œë¬¸ì´ê³ , ë‘ ìš©ì–´ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ì˜ë¯¸ë¥¼ ê°–ê³  ìˆê¸° ë•Œë¬¸ì— í˜¼ë™ì„ ì•¼ê¸°í•  ê°€ëŠ¥ì„±ì´ ë‹¤ë¶„í•´ìš”.
ê·¸ë˜ì„œ ì´ ìš©ì–´ëŠ” ì˜ë¬¸ ë‹¨ì–´ ê·¸ìì²´ë¡œ ì˜ë¯¸ë¥¼ ë°›ì•„ë“¤ì´ê¸°ë¡œ í•˜ê³  ë“¤ì–´ê°€ ë´…ì‹œë‹¤.
&lt;img src=&quot;../../assets/built/images/lec3_img_7.png&quot; alt=&quot;img_7.png&quot; /&gt;
ê°•ì˜ì—ì„œ ì„¤ëª…í•˜ëŠ” ë‚´ìš©ì„ ê°„ë‹¨íˆ ìš”ì•½í•˜ìë©´, Overfittingì„ ë§‰ê¸° ìœ„í•´ì„œ, ì¦‰ â€˜ëª¨ë¸ì˜ ìœµí†µì„±ì„ ê¸°ë¥´ê¸° ìœ„í•´ì„œâ€™ ì¶”ê°€ë¡œ Loss functionì— ë”í•´ì£¼ëŠ” ì‘ì—…ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
ì´ ìš”ì†Œë¥¼ ë”í•´ì£¼ì§€ ì•Šìœ¼ë©´, Lossë¥¼ ìµœëŒ€í•œ ì¤„ì´ë„ë¡ parameterë¥¼ ì„¤ì •í•˜ê²Œ ë˜ì—ˆë”ë¼ë„ ê²°êµ­ ìƒˆë¡œìš´ test dataì—ëŠ” ë‚®ì€ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ë³´ì´ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.
ë‹¤ì‹œ ë§í•´, Loss functionì„ ë‹¨ìˆœíˆ ì¤„ì´ëŠ” ê²ƒë§Œì´ ëŠ¥ì‚¬ëŠ” ì•„ë‹ˆë¼ëŠ” ê²ƒì´ì§€ìš”.&lt;/p&gt;

&lt;p&gt;ì—¬ê¸°ì„œ $\lambda$ëŠ” ìš°ë¦¬ê°€ ì„¤ì •í•´ì£¼ì–´ì•¼ í•  hyperparameterì´ë©°, $R(W)$ ìš°ë¦¬ê°€ ë”í•´ì§€ëŠ” ê°’ì— ì ìš©í•  í˜ë„í‹°ì—ìš”.
ë³¸ ê°•ì˜ì—ì„œëŠ” L2 Regularizationì„ ì†Œê°œí•˜ë©´ì„œ weight ì›ì†Œë“¤ì˜ ì œê³±ê°’ì„ $R(W)$ ë¡œ ì •ì˜í•´ì„œ Loss functionì— í˜ë„í‹°ë¥¼ ì£¼ì—ˆì–´ìš”.
í˜ë„í‹°ë¥¼ ì£¼ì—ˆë‹¤ëŠ” ì–˜ê¸°ëŠ”, $R(W)$ ì˜ í¬ê¸°ê°€ í´ìˆ˜ë¡ ëª¨ë¸ì˜ ë³µì¡ë„ë¥¼ ë‚®ì¶”ëŠ” ë°©í–¥ìœ¼ë¡œ updateí•˜ë„ë¡ í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•˜ëŠ” ê±°ì—ìš”.&lt;br /&gt;
&lt;a href=&quot;https://www.notion.so/Lecture-3-Loss-functions-and-Optimization-3c46c15413324bc7856387118e6cfff1#f4708d3b84444fb7be5d93b71805083b&quot;&gt;L1, L2 Regularization&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Regularizationì—ëŠ” L1, L2 regularization ë§ê³ ë„ &lt;strong&gt;Dropout, Batch Normaization&lt;/strong&gt; ë“± ë§¤ìš° ìì£¼ ì“°ì´ë©° ì¤‘ìš”í•˜ê²Œ ë‹¤ë£¨ì–´ì§€ëŠ” ë°©ë²•ë“¤ì´ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì˜¤ëŠ˜ ë‚´ìš©ì´ ì¡°ê¸ˆ ì–´ë µë‹¤ë©´ ê´œì°®ìŠµë‹ˆë‹¤. ë‹¤ìŒì— ë˜ ë‹¤ì‹œ ë³´ë©´ì„œ Regularizationì— ëŒ€í•œ ì§ê´€ì„ ì–»ê³ ,
ì˜¤ëŠ˜ì€ &lt;strong&gt;Overfittingì„ ë§‰ê¸° ìœ„í•œ ê³¼ì •&lt;/strong&gt;ëŠ” ì‚¬ì‹¤ë§Œ ìš°ì„ ì ìœ¼ë¡œ ê¸°ì–µí•˜ê³  ë„˜ì–´ê°‘ì‹œë‹¤!&lt;/p&gt;

&lt;h3 id=&quot;softmax-function&quot;&gt;Softmax function&lt;/h3&gt;
&lt;p&gt;scoreë¥¼ ê¸°ë°˜ìœ¼ë¡œ, logë¥¼ í¬í•¨í•œ íŠ¹ì •í•œ ì—°ì‚°ì„ ì§„í–‰í•˜ê³ , multiclassì— ëŒ€í•œ í™•ë¥ ê°’ì„ return ë°›ëŠ” ë˜ë‹¤ë¥¸ Loss functionì…ë‹ˆë‹¤.
ì´ëŠ” ì°¨í›„ ìµí˜€ì•¼ í•  cross-entropyì™€ë„ ì—°ê´€ë˜ì–´ ìˆëŠ” ë§¤ìš° ì¤‘ìš”í•œ ê°œë…ì´ë‹ˆ ì˜ ìµí˜€ë‘¡ì‹œë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/lec3_img_8.png&quot; alt=&quot;img_8.png&quot; /&gt;
ìœ„ ìŠ¬ë¼ì´ë“œì— êµ‰ì¥íˆ ë§ì€ ë‚´ìš©ì´ í•¨ì¶•ë˜ì–´ ìˆìœ¼ë‹ˆ ì£¼ì˜ê¹Šê²Œ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;optimization&quot;&gt;Optimization&lt;/h2&gt;
&lt;h3 id=&quot;stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/h3&gt;

&lt;h2 id=&quot;ì§ˆë¬¸&quot;&gt;ì§ˆë¬¸&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;softmax functionì—ì„œ logë¥¼ ì“°ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?&lt;/li&gt;
  &lt;li&gt;multiclass SVM Loss ëŠ” ì™œ SVM Lossë¼ëŠ” ì´ë¦„ì´ ë¶™ì—ˆì„ê¹Œìš”?&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>ê±´ë„ˆë³„(crosstar)</name>
        
        
      </author>

      

      
        <category term="ML" />
      

      
        <summary type="html">GOAL parameterë¥¼ Loss functionì„ í†µí•´ updateí•˜ëŠ” optimization ê³¼ì •ì„ ì´í•´í•©ë‹ˆë‹¤. Gradient descent ê³¼ì •ì„ ê°œê´„ì ìœ¼ë¡œ ì´í•´í•©ë‹ˆë‹¤.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">CS231n Lecture 2. Image Classification</title>
      <link href="https://crosstar1228.github.io/cs231n-lec2" rel="alternate" type="text/html" title="CS231n Lecture 2.  Image Classification" />
      <published>2021-10-11T11:00:00+00:00</published>
      <updated>2021-10-11T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/cs231n-lec2</id>
      <content type="html" xml:base="https://crosstar1228.github.io/cs231n-lec2">&lt;h1 id=&quot;goal&quot;&gt;GOAL&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Data-Driven Approachë¡œ image classificationì„ ì§„í–‰í•˜ê²Œ ëœ ë°°ê²½ì„ ì´í•´í•©ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;ì´ë¯¸ì§€ë¥¼ ì–´ë–»ê²Œ ë¹„êµ ë° ë¶„ë¥˜í•˜ëŠ”ì§€ ì•Œì•„ë³´ê³ , &lt;strong&gt;KNN(K-Nearest Neighbor)&lt;/strong&gt;ì— ê´€í•˜ì—¬ ì´í•´í•©ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” Linear í•œ ëª¨ë¸ì— ê´€í•˜ì—¬ ê°€ë³ê²Œ ì´í•´í•´ ë´…ë‹ˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#image-classification&quot;&gt;Image Classifciation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#data-driven-approach&quot;&gt;Data-Driven Approach&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#distance-metric&quot;&gt;Distance Metric&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#L1,-L2-distance&quot;&gt;L1, L2 Distance&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#k-nearest-neighbor&quot;&gt;K-Nearest Neighbor&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#hyperparameter&quot;&gt;Hyperparameter&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#linear-classifier&quot;&gt;Linear Classifier&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#limitations&quot;&gt;Limitations&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;image-classification&quot;&gt;Image Classification&lt;/h2&gt;
&lt;p&gt;Computer Visionì—ì„œ Image Classificationì€ ë§¤ìš° í•µì‹¬ì ì´ê³  ê·¼ë³¸ì ì¸ ì‘ì—…ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ìš°ë¦¬ê°€ ì§ê´€ì ìœ¼ë¡œ ì¸ì‹í•˜ëŠ” ê²ƒì´ë‘, ì»´í“¨í„°ê°€ ì¸ì‹í•˜ëŠ” ê²ƒì´ë‘ì€ ì°¨ì´ê°€ ìˆì£ . ì»´í“¨í„°ëŠ” ëª¨ë“  ê²ƒì„ ìˆ«ìë¡œ ë°›ì•„ë“¤ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ê²ƒì„ â€˜Semantic Gap(ì˜ë¯¸ë¡ ì  ì°¨ì´)â€™ë¼ê³  í‘œí˜„í•˜ë©°, ì•„ë˜ ê·¸ë¦¼ì„ ë³´ë©°ì´í•´í•´ ë³´ê² ìŠµë‹ˆë‹¤.&lt;br /&gt;
&lt;img src=&quot;../../assets/built/images/cs2_img.png&quot; alt=&quot;cs2_img.png&quot; /&gt;
ì»´í“¨í„°ì—ì„œ ì´ë¯¸ì§€ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ 0~255ì‚¬ì´ì˜ pixelë¡œ í‘œí˜„ë˜ë©°, 3ê°œì˜ channelì˜ matrixí˜•íƒœë¡œ í‘œí˜„ë©ë‹ˆë‹¤.&lt;br /&gt;
-&amp;gt; ì´ëŸ° ìˆ«ìë¡œë¶€í„° ìš°ë¦¬ëŠ” &lt;strong&gt;â€˜ì´ ì‚¬ì§„ì´ ê³ ì–‘ì´ë‹¤â€™ë¼ëŠ” ì˜ë¯¸ë¥¼ ì¶”ì¶œí•´ ë‚´ê³  ì‹¶ì€ ê²Œ ëª©ì &lt;/strong&gt;ì…ë‹ˆë‹¤.
í•˜ì§€ë§Œ ë¹›, ë³€í˜•, ë³´í˜¸ìƒ‰, ê°œì²´ì˜ ë³€í˜• ë“± ë§ì€ Hurdleì´ ì¡´ì¬í•˜ê¸°ì—, ëª…ë°±í•œ ë°©ë²•ì´ ì—†ì—ˆì£ . ê°€ì¥ìë¦¬ ëª¨ì„œë¦¬ë¥¼ ë”°ë¼ outlineì„ ë§Œë“¤ì–´ë‚´ë©° ì¶”ì¶œí•˜ëŠ” ì‹œë„ë“¤ì´ ìˆì—ˆì§€ë§Œ ì‰½ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
ê·¸ë˜ì„œ ê³ ì•ˆëœ ë°©ë²•ì´ Dataì— ê¸°ë°˜í•œ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;data-driven-approach&quot;&gt;Data-Driven Approach&lt;/h2&gt;
&lt;p&gt;ê°„ë‹¨í•œ ìˆœì„œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;ì´ë¯¸ì§€ì™€ label(ì´ë¯¸ì§€ì˜ ì •ë‹µ)ì •ë³´ê°€ í¬í•¨ëœ datasetì„ ëª¨ìœ¼ê³ &lt;/li&gt;
  &lt;li&gt;ë¨¸ì‹ ëŸ¬ë‹ìœ¼ë¡œ training ì‹œí‚¤ê³ &lt;/li&gt;
  &lt;li&gt;ìƒˆë¡œìš´ ì´ë¯¸ì§€ì— ëŒ€í•œ classifier(ë¶„ë¥˜ê¸°)ë¥¼ í‰ê°€í•´ ë³´ëŠ” ê²ƒ
&lt;img src=&quot;../../assets/built/images/cs2_img_1.png&quot; alt=&quot;cs2_img_1.png&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;-&amp;gt; training setì„ labelê³¼ í•¨ê»˜ í•™ìŠµí•˜ë©´, ê·¸ ì´í›„ì˜ ìƒˆë¡œìš´ ì´ë¯¸ì§€ì— ëŒ€í•˜ì—¬ ë¶„ë¥˜ë¥¼ í†µí•´ ì˜ë¯¸ë¥¼ ì¶”ì¶œí•´ ë‚¼ ìˆ˜ ìˆëŠ” ê²ƒì´ì£ .
ê·¸ë ‡ë‹¤ë©´ ì–´ë–»ê²Œ ê¸°ì¡´ í•™ìŠµëœ ë°ì´í„°ì™€ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ë¹„êµí•  ê²ƒì´ëƒ? í•˜ëŠ” ì˜ë¬¸ì´ ì œê¸°ë˜ëŠ”ë°,
ê¸°ë³¸ì ìœ¼ë¡œ ìƒˆë¡œìš´ ì´ë¯¸ì§€ì™€ ê¸°ì¡´ í•™ìŠµëœ ì´ë¯¸ì§€ ê°„ì˜ ê±°ë¦¬ë¥¼ ì¬ì–´ ê°€ì¥ ê±°ë¦¬ê°€ ê°€ê¹Œìš´ ì´ë¯¸ì§€ë¥¼ ê³ ë¥´ê²Œ ë©ë‹ˆë‹¤.
ì´ê²ƒì„ nearest neighbor(ê°€ì¥ ê°€ê¹Œì´ ìˆëŠ” ì´ì›ƒ)ë°©ë²•ì´ë¼ê³  í•©ë‹ˆë‹¤.&lt;br /&gt;
ì•„ë˜ ê·¸ë¦¼ì€ nearest neighborì— ëŒ€í•´ 10ê°œì˜ classì— ë”°ë¼ ê°ê° ì˜ˆì¸¡ì´ ë˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cs2_img_2.png&quot; alt=&quot;cs2_img_2.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;distance-metric&quot;&gt;Distance Metric&lt;/h2&gt;
&lt;p&gt;ê°€ê¹ê³  ë¨¼ ê±°ë¦¬(Distance)ë¥¼ ì¸¡ì •í•˜ë ¤ë©´ ê¸°ì¤€ì´ í•„ìš”í•©ë‹ˆë‹¤. ê°•ì˜ì—ì„œëŠ” ì•„ë˜ ë‘ ê°€ì§€ ê¸°ì¤€ì„ ì„¤ëª…í•´ì£¼ê³  ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;
&lt;h3 id=&quot;l1-l2-distance&quot;&gt;L1, L2 Distance&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cs2_img_4.png&quot; alt=&quot;cs2_img_4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;L1 distance : ê° pixelê°’ì˜ ì°¨ì´ë¥¼ êµ¬í•œ í›„ ê²°ê´ê°’ì„ í•©ì‚°í•˜ëŠ” ë°©ë²•&lt;br /&gt;
L2 distance : ê° pixelê°’ì˜ ì°¨ì´ë¥¼ ì œê³±í•œ í›„ rootë¥¼ ì”Œìš´ í›„ ê²°ê´ê°’ì„ í•©ì‚°í•˜ëŠ” ë°©ë²•&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;L2 distanceëŠ” rootë¥¼ ì”Œìš°ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ ì •ì˜ë˜ê¸°ë„ í•©ë‹ˆë‹¤.&lt;/li&gt;
  &lt;li&gt;L1ê³¼ L2 distanceì™€ ê´€ë ¨í•œ ì¶”ê°€ì ì¸ ì´í•´ëŠ” &lt;a href=&quot;https://junklee.tistory.com/29&quot;&gt;ë§í¬&lt;/a&gt;ë¥¼ ì°¸ê³ í•´ ì£¼ì„¸ìš”.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;L1 distance ë°©ë²•ì„ í†µí•˜ì—¬ ê±°ë¦¬ë¥¼ ê³„ì‚°í•œ ì•„ë˜ ì˜ˆì‹œë¥¼ ë³´ë©° ì´í•´í•´ ë´…ì‹œë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cs2_img_3.png&quot; alt=&quot;cs2_img_3.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;k-nearest-neighbor&quot;&gt;K-Nearest Neighbor&lt;/h3&gt;
&lt;p&gt;í•œë§ˆë””ë¡œ ê°€ì¥ ê°€ê¹Œìš´ Kê°œë¥¼ ë¹„êµí•´ ë³´ì! ì…ë‹ˆë‹¤. k=5ë¼ë©´, ê°€ì¥ ê±°ë¦¬ê°€ ê°€ê¹Œìš´ 5ê°œì¤‘ì—ì„œ ë‹¤ìˆ˜ê²°ë¡œ ì˜ˆì¸¡ì„ ì§„í–‰í•˜ëŠ” ê²ƒì´ì—ìš”!
ì•„ë˜ ì½”ë“œë¥¼ ì‚´í´ë³´ë©° ì´í•´í•´ ë³¼ê¹Œìš”?
{gist}&lt;/p&gt;

&lt;p&gt;í•˜ì§€ë§Œ ì´ëŠ” ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;ì „ì²´ í•™ìŠµëœ ë°ì´í„°ì…‹ê³¼ ë¹„êµí•˜ê¸° ë•Œë¬¸ì— ë„ˆë¬´ ëŠë¦¬ê³ ,&lt;/li&gt;
  &lt;li&gt;outlierì— ê°•ê±´í•˜ì§€ ëª»í•©ë‹ˆë‹¤.&lt;br /&gt;
ì•„ë˜ ê·¸ë¦¼ì„ ë³´ì‹œì£ !
&lt;img src=&quot;../../assets/built/images/cs2_img_5.png&quot; alt=&quot;cs2_img_5.png&quot; /&gt;
ì ë“¤ì€ ê°ê°ì˜ dataë¥¼ ì˜ë¯¸í•˜ê³ , ìƒ‰ê¹”ì€ KNNì— ì˜í•´ ë¶„ë¥˜ëœ ê²°ê³¼ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´, ì´ˆë¡ìƒ‰ì´ ê³ ì–‘ì´ë¥¼ ì˜ë¯¸í•˜ê³  ë…¸ë€ìƒ‰ì´ ê°•ì•„ì§€ë¥¼ ì˜ë¯¸í•œë‹¤ë©´, ì´ˆë¡ìƒ‰ ì˜ì—­ ì•ˆì— í¬í•¨ëœ dataë“¤ì´ ê³ ì–‘ì´ë¡œ ë¶„ë¥˜ëœ ê²ƒì´ì£ .
í•˜ì§€ë§Œ ì¡°ê¸ˆ ì´ìƒí•œ ì ì€, ì¤‘ê°„ì— ì„¬ì²˜ëŸ¼ ë–¨ì–´ì ¸ ìˆëŠ” ë…¸ë€ìƒ‰ ì§€ì ì…ë‹ˆë‹¤. ì´ˆë¡ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ” ê²ƒì´ ìì—°ìŠ¤ëŸ¬ì›€ì—ë„ ë¶ˆêµ¬í•˜ê³ , distanceê°€ ë” ê°€ê¹ë‹¤ëŠ” ì´ìœ ë§Œìœ¼ë¡œ ê°•ì•„ì§€ë¡œ ë¶„ë¥˜ëœ ê²ƒì…ë‹ˆë‹¤. ì‹¤ì œë¡œ dataë¥¼ í™•ì¸í•´ ë´¤ì„ ë•Œ, ì´ê²ƒì€ ê³ ì–‘ì´ì¼ í™•ë¥ ì´ ë†’ê³ , KNN ì•Œê³ ë¦¬ì¦˜ì´ ì˜ëª» ì˜ˆì¸¡í•˜ì˜€ì„ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤.
(ë‹¤ì‹œ ë§í•´, ê°•ì•„ì§€ë¼ê³  í•™ìŠµëœ ë°ì´í„°ì™€ ê±°ë¦¬ê°€ ê°€ê¹ë‹¤ëŠ” ì´ìœ ë§Œìœ¼ë¡œ, ì‹¤ì œë¡œ ê³ ì–‘ì´ë¡œ ë¶„ë¥˜ë˜ëŠ” ê²ƒì´ ë” ì ì ˆí•¨ì—ë„ ê°•ì•„ì§€ë¡œ ë¶„ë¥˜ëœ ê²ƒì…ë‹ˆë‹¤.)
ì´ëŸ¬í•œ ë‹¨ì  ë•Œë¬¸ì— KNNì€ ê±°ì˜ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ëŠ” ë˜í•œ &lt;strong&gt;ì°¨ì›ì˜ ì €ì£¼&lt;/strong&gt; ê°œë…ê³¼ë„ ì—°ê´€ë˜ì–´ ìˆëŠ”ë°, ì´ëŠ” ë‚˜ì¤‘ì— ë‹¤ë£¨ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ì¶”ê°€ë¡œ, Kì˜ ìˆ˜ì— ë”°ë¼ ë¶„ë¥˜ ì„±ëŠ¥ ë° ê²°ê³¼ë„ ë‹¬ë¼ì§€ê²Œ ë˜ëŠ”ë°, &lt;a href=&quot;http://vision.stanford.edu/teaching/cs231n-demos/knn/&quot;&gt;ë§í¬&lt;/a&gt;ì—ì„œ ì‹¤í—˜í•´ë³´ë©´ì„œ ì´í•´í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤!&lt;/p&gt;

&lt;h3 id=&quot;hyperparameter&quot;&gt;Hyperparameter&lt;/h3&gt;
&lt;p&gt;ê·¸ë ‡ë‹¤ë©´ ìµœì ì˜ Kê°’ì€ ì–´ë–»ê²Œ ì„¤ì •í•  ìˆ˜ ìˆì„ê¹Œìš”? ë˜, ì–´ë– í•œ ê¸°ì¤€ìœ¼ë¡œ ê±°ë¦¬(distance)ë¥¼ ì¸¡ì •í•˜ëŠ” ê²ƒì´ ë³´ë‹¤ ë‚˜ì€ ì„±ëŠ¥ì„ ì•ˆê²¨ì¤„ê¹Œìš”?
ê·¸ê²ƒì€ ìš°ë¦¬ê°€ ëª¨ë¸ì„ ì§ì ‘ ëŒë ¤ê°€ë©´ì„œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì´ ë‚˜ì˜¬ ìˆ˜ ìˆê²Œ ì¡°ì •ì„ í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤(problem-dependent).&lt;br /&gt;
ì•Œê³ ë¦¬ì¦˜ ë° ëª¨ë¸ì— ë”°ë¼ ì´ëŸ¬í•œ ê¸°ë³¸ì ì¸ settingì— í•„ìš”í•œ ê°’ì„ ìš°ë¦¬ëŠ” &lt;strong&gt;hyperparameter&lt;/strong&gt;ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤!&lt;/p&gt;

&lt;p&gt;ì´ê²ƒì€ ëª¨ë¸ì´ ìì²´ì ìœ¼ë¡œ í•™ìŠµí•˜ê³  updateí•˜ëŠ” parameterì™€ ëŒ€ë¹„ë©ë‹ˆë‹¤. ì´ê²ƒì— ëŒ€í•œ ì„¤ëª…ì€ ë§ì´ í•  ìˆ˜ ìˆëŠ” ê¸°íšŒê°€ ìˆì„ ê²ƒì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cs2_img_6.png&quot; alt=&quot;cs2_img_6.png&quot; /&gt;
HyperparameterëŠ” ì´ datasetì„ training, validation(ìƒëµë˜ê¸°ë„ í•¨), test set ì´ë ‡ê²Œ ì„¸ ê°€ì§€ë¡œ ë‚˜ëˆ„ì–´ í•™ìŠµì„ ì§„í–‰í•˜ë©´ì„œ ì¡°ì •ë©ë‹ˆë‹¤.&lt;br /&gt;
&lt;strong&gt;ë¶„ë¥˜ ëª¨ë¸ë§ ì‹œ ê¸°ë³¸ì´ ë˜ëŠ” êµ¬ì¡°&lt;/strong&gt;ì´ë‹ˆ ì˜ ê¸°ì–µí•´ ë‘ì‹œë©´ ì¢‹ìŠµë‹ˆë‹¤!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;h3 id=&quot;tip&quot;&gt;TipğŸ¥³&lt;/h3&gt;
  &lt;p&gt;ìœ„ ìŠ¬ë¼ì´ë“œë¥¼&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;trainset = ì‹œí—˜ê³µë¶€ ë²”ìœ„&lt;/li&gt;
    &lt;li&gt;validation set = ëª¨ì˜ê³ ì‚¬&lt;/li&gt;
    &lt;li&gt;test set = ìˆ˜ëŠ¥ ì‹œí—˜
      &lt;blockquote&gt;
        &lt;p&gt;ì´ë¼ê³  ìƒê°í•˜ê³  í•œ ë²ˆ ì´í•´í•´ ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤!
  &lt;img src=&quot;../../assets/built/images/cs2_img_7.png&quot; alt=&quot;cs2_img_7.png&quot; /&gt;&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;ì´ì™€ ë‹¬ë¦¬ trainsetì„ ì—¬ëŸ¬ Fold(subset)ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ê²€ì¦(validation)í•˜ëŠ” ë°©ë²•ë„ ìˆìŠµë‹ˆë‹¤. ê° Foldë³„ë¡œ ê²°ê³¼ë¥¼ í‰ê· ë‚´ì–´ ì‚°ì¶œí•©ë‹ˆë‹¤. ê²€ì¦ì„ ì—¬ëŸ¬ ë²ˆ ì‹œë„í•  ìˆ˜ ìˆëŠ” ì¥ì ì´ ìˆê² ë„¤ìš”!&lt;/p&gt;

&lt;h2 id=&quot;linear-classifier&quot;&gt;Linear Classifier&lt;/h2&gt;

&lt;p&gt;ìš°ë¦¬ëŠ” ì–´ë–»ê²Œ ì´ë¯¸ì§€ ê°„ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ê³ , ì´ë¯¸ì§€ì—ì„œ ì˜ë¯¸ë¥¼ ë½‘ì•„ë‚´ì–´ ë¶„ë¥˜í•˜ëŠ”ì§€ ê·¸ ë°©ë²•ì— ëŒ€í•˜ì—¬ ë°°ì› ìŠµë‹ˆë‹¤. ê·¸ê²ƒì— ê¸°ë°˜í•˜ì—¬ ì‹¤ì œ ë¶„ë¥˜ë¥¼ í•˜ëŠ” ì‘ì—…ì„ ì‚´í´ë´…ì‹œë‹¤.&lt;br /&gt;
10ê°œì˜ classë¡œ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì´ë©°, 50,000ê°œì˜ trainsetê³¼ 10,000ê°œì˜ testsetìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆëŠ” &lt;a href=&quot;https://www.cs.toronto.edu/~kriz/cifar.html&quot;&gt;CIFAR10&lt;/a&gt; datsetì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cs2_img_8.png&quot; alt=&quot;cs2_img_8.png&quot; /&gt;
ê³ ì–‘ì´ imageë¥¼ input(x)ìœ¼ë¡œ ë„£ìœ¼ë©´, ìš°ë¦¬ê°€ ì„¤ì •í•œ ëª¨ë¸(f(x,W))ì˜ ì—°ì‚°ì— ì˜í•´ 10ê°œì˜ class ì— ëŒ€í•œ ê°ê°ì˜ score(ì ìˆ˜)ë¥¼ outputìœ¼ë¡œ í™•ì¸í•˜ê²Œ ë©ë‹ˆë‹¤.
ì´ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ classë¡œ ëª¨ë¸ì€ ì˜ˆì¸¡ì„ í•˜ê²Œ ë˜ëŠ” ê²ƒì´ì£ !&lt;br /&gt;
ì—¬ê¸°ì„œ WëŠ” Weight ë˜ëŠ” Parameterë¼ê³  í•˜ë©°, inputìœ¼ë¡œë¶€í„° outputì„ ë°˜í™˜í•´ ì£¼ëŠ” ê°€ì¤‘ì¹˜ì˜ ì—­í• ì„ í•˜ëŠ” ë§¤ìš° ì¤‘ìš”í•œ ê°œë…ì…ë‹ˆë‹¤.&lt;br /&gt;
ì—¬ê¸°ì„œ bëŠ” ê²°ê´ê°’ì„ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ëª¨ë¸ë¡œ ê·¼ì‚¬í•˜ë„ë¡ ì¡°ì •í•´ì£¼ëŠ” ê°’ì…ë‹ˆë‹¤. ì´ëŠ” Lecture 3 ì—ì„œ ìì„¸íˆ ë‹¤ë¤„ë³´ê² ìŠµë‹ˆë‹¤.&lt;br /&gt;
ì•„ë˜ ìŠ¬ë¼ì´ë“œë¥¼ ë³´ë©° ì œê°€ ì„¤ëª…í•œ ë‚´ìš©ì„ ì´í•´í•´ ë³´ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/cs2_img_9.png&quot; alt=&quot;cs2_img_9.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ê²°ê³¼ì ìœ¼ë¡œ, linearí•œ ëª¨ë¸ë¡œë¶€í„° ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´ ë¶„ë¥˜ ì‘ì—…ì´ ì´ë£¨ì–´ì§€ê²Œ ë©ë‹ˆë‹¤.
&lt;img src=&quot;../../assets/built/images/cs2_img_10.png&quot; alt=&quot;cs2_img_10.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;limitations&quot;&gt;Limitations&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;ë¹„ì„ í˜• ëª¨ë¸ë§ì´ ì–´ë µìŠµë‹ˆë‹¤. ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´, ë¹„ì„ í˜•í•œ í•¨ìˆ˜ë¡œë¶€í„° ë§Œë“¤ì–´ì§„ classë¡œ ë¶„ë¥˜ì‘ì—…ì„ ì§„í–‰í•  ìˆ˜ ì—†ì£ .
&lt;img src=&quot;../../assets/built/images/cs2_img_11.png&quot; alt=&quot;cs2_img_11.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;parameterë¥¼ ìŠ¤ìŠ¤ë¡œ updateí•˜ì§€ ëª»í•©ë‹ˆë‹¤.&lt;/strong&gt; ìš°ë¦¬ëŠ” ì´ê²ƒì´ ì¢‹ì€ ëª¨ë¸ì¸ì§€ ì•„ë‹Œì§€ ê·¸ì € ê²°ê³¼ë§Œ ë³´ê³  íŒë‹¨í•˜ëŠ” ìˆ˜ë°–ì— ì—†ìœ¼ë‹ˆ, ì¼ì¼ì´ ëª¨ë¸ì˜ parameter Wë¥¼ ìˆ˜ì •í•´ ì£¼ì–´ì•¼ í•˜ëŠ” ê²ƒì´ì£ .
&lt;img src=&quot;../../assets/built/images/cs2_img_12.png&quot; alt=&quot;cs2_img_12.png&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ì´ëŸ¬í•œ ì˜ë¬¸ì„ ê°–ê³  ë‹¤ìŒ ê°•ì˜ì—ì„œ ì–´ë–»ê²Œ ëª¨ë¸ì„ ìµœì í™”(optimize)í•˜ëŠ”ì§€ ë°°ì›Œë³´ê² ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;##íšŒê³ ğŸ˜&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;ì´ë¯¸ì§€ì˜ ì˜ë¯¸ë¡ ì ì¸ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•´ data-driven approachê°€ ê³ ì•ˆë˜ì—ˆê³ , ì´ëŠ” training setì„ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒì´ë‹¤.&lt;/li&gt;
    &lt;li&gt;KNNìœ¼ë¡œ Kê°œì˜ ê°€ì¥ distanceê°€ ì‘ì€ imageì™€ì˜ ë¹„êµë¥¼ í†µí•´ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜ ê°€ëŠ¥í•˜ì§€ë§Œ, ì˜ ì“°ì´ì§€ëŠ” ì•ŠëŠ”ë‹¤.&lt;/li&gt;
    &lt;li&gt;linearí•œ classificationì€ ëª¨ë¸ ìµœì í™”ì— ì–´ë ¤ì›€ì´ ìˆë‹¤.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;ìƒê°í•´-ë³¼-ë¬¸ì œ&quot;&gt;ìƒê°í•´ ë³¼ ë¬¸ì œ!&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;hyperparameterë¥¼ ì²˜ìŒì— ê°’ì„ ì •í•˜ëŠ” ê·¼ê±°ê°€ í•„ìš”í•´ìš”. ì²˜ìŒì— ì–´ë–»ê²Œ ì •í• ê¹Œìš”?&lt;/li&gt;
  &lt;li&gt;k-fold validationì€ ì™œ ì‘ì€ datasetì—ë§Œ ìœ ìš©í• ê¹Œìš”?&lt;/li&gt;
  &lt;li&gt;linear classificationì—ì„œ linearì˜ ì˜ë¯¸ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;CS231n Lecture 2 : https://youtu.be/OoUX-nOEjG0&lt;/li&gt;
  &lt;li&gt;CS231n Lecture slide : http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture2.pdf&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>ê±´ë„ˆë³„(crosstar)</name>
        
        
      </author>

      

      
        <category term="ML" />
      

      
        <summary type="html">GOAL Data-Driven Approachë¡œ image classificationì„ ì§„í–‰í•˜ê²Œ ëœ ë°°ê²½ì„ ì´í•´í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ì–´ë–»ê²Œ ë¹„êµ ë° ë¶„ë¥˜í•˜ëŠ”ì§€ ì•Œì•„ë³´ê³ , KNN(K-Nearest Neighbor)ì— ê´€í•˜ì—¬ ì´í•´í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” Linear í•œ ëª¨ë¸ì— ê´€í•˜ì—¬ ê°€ë³ê²Œ ì´í•´í•´ ë´…ë‹ˆë‹¤.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">CS231n Lecture 12. Visualizing and understanding</title>
      <link href="https://crosstar1228.github.io/cs231n-lec12" rel="alternate" type="text/html" title="CS231n Lecture 12. Visualizing and understanding" />
      <published>2021-09-16T11:00:00+00:00</published>
      <updated>2021-09-16T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/cs231n-lec12</id>
      <content type="html" xml:base="https://crosstar1228.github.io/cs231n-lec12">&lt;h1 id=&quot;goal&quot;&gt;GOAL&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;ì‹œê°í™”ë¥¼ í†µí•´ CNNì˜ featureë¥¼ ì´í•´í•˜ëŠ” ë°©ë²•ë¡ ë“¤ì„ activationê³¼ gradientì˜ ê´€ì ì—ì„œ ì•Œì•„ë³¸ë‹¤.&lt;/li&gt;
  &lt;li&gt;ì´ë¯¸ì§€ Styleì„ ë³€í˜•ì‹œí‚¤ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#deepdream&quot;&gt;Deepdream&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#feature-inversion&quot;&gt;Feature Inversion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#texture-synthesis&quot;&gt;Texture Synthesis&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#gram-matrix&quot;&gt;Gram Matrix&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#style-transfer&quot;&gt;Style Transfer&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#fast-style-transfer&quot;&gt;Fast Style Trnasfer&lt;/a&gt;
        &lt;h2 id=&quot;layers&quot;&gt;Layers&lt;/h2&gt;
      &lt;/li&gt;
      &lt;li&gt;first layer&lt;/li&gt;
      &lt;li&gt;last layer -&amp;gt; feature nearest&lt;/li&gt;
      &lt;li&gt;t-SNE dimensionality reduction
        &lt;h2 id=&quot;deepdream&quot;&gt;Deepdream&lt;/h2&gt;
        &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; - [ìœ„í‚¤ë°±ê³¼ : Deepdream](https://en.wikipedia.org/wiki/DeepDream)  
 - [ì´ë¯¸ì§€ ì‚¬ì´íŠ¸ ì²´í—˜](https://deepdreamgenerator.com/)
 - Google ì—ì„œ ë§Œë“  ì¬ë¯¸ìš©
 - networkì˜ ì¤‘ê°„ì— **íŠ¹ì •í•œ neuron activationì„ Amplify(ì¦í­)**  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;-&amp;gt; ë„¤íŠ¸ì›Œí¬ê°€ ì´ë¯¸ ë½‘ì•„ë‚¸ íŠ¹ì§•ë“¤ì„ ë”ìš± ì¦í­ì‹œí‚¤ëŠ” ì—­í• &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ì›ë¦¬
    &lt;ol&gt;
      &lt;li&gt;forward ë°©í–¥ìœ¼ë¡œ activation ê³„ì‚° (ì—¬ê¸°ê¹Œì§„ ì¼ë°˜ì  ë„¤íŠ¸ì›Œí¬ì™€ ê°™ìŒ)&lt;/li&gt;
      &lt;li&gt;layerì˜ &lt;strong&gt;&lt;em&gt;activation ê³¼ ê°™ì€&lt;/em&gt; gradientë¥¼ ì„¤ì •&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;Backward ë°©í–¥ìœ¼ë¡œ gradient ê³„ì‚° (backprop)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;ê²°ê³¼ë¥¼ ìœ„í•´ ì¡°ì •í•œ ì‚¬í•­ë“¤
    &lt;ol&gt;
      &lt;li&gt;Jitter : ì´ë¯¸ì§€ë¥¼ ë‘ í”½ì…€ì”© ì˜®ê¹€&lt;/li&gt;
      &lt;li&gt;Normalize ascent to gradient&lt;/li&gt;
      &lt;li&gt;Clip pixel values :ìµœëŒ€,ìµœì†Ÿê°’ìœ¼ë¡œ ì œí•œ&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;-&amp;gt; training ë˜ì—ˆë˜ imageë“¤ì˜ featureë“¤ì´ input imageì— í•¨ê»˜ ë’¤ì„ì—¬ ë‚˜íƒ€ë‚¨
&lt;img src=&quot;../../assets/built/images/img_1.png&quot; alt=&quot;img_1.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;feature-inversion&quot;&gt;feature Inversion&lt;/h2&gt;

&lt;p&gt;ì´ë¯¸ì§€ì˜ CNN feature Vector ê°€ ì£¼ì–´ì¡Œì„ ë•Œ&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;ìì—°ìŠ¤ëŸ½ê³ &lt;/li&gt;
  &lt;li&gt;ê·¸ feature vector ê°€ì¥ ì˜ ë¶€í•©í•˜ëŠ”&lt;br /&gt;
&lt;strong&gt;ì´ë¯¸ì§€ output return&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_2.png&quot; alt=&quot;img_2.png&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;ì£¼ì–´ì§„ feature vectorì™€&lt;/li&gt;
  &lt;li&gt;ìƒˆë¡œìš´ ì´ë¯¸ì§€ì˜ featureì™€ì˜ L2 distance ì¸¡ì • &lt;br /&gt;
Regularization ì§„í–‰ í›„ &lt;strong&gt;ìµœì†Ÿê°’ì„ return&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_3.png&quot; alt=&quot;img_3.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;VGG16ì˜ ê°ê¸° ë‹¤ë¥¸ layerë¡œë¶€í„° feature inversion ì§„í–‰ ê²°ê³¼,&lt;br /&gt;
  -&amp;gt; ì–•ì€ layerë³´ë‹¤ëŠ” ê¹Šì€ layerì—ì„œ ë” ìƒˆë¡œìš´ outputì´ íƒ„ìƒí•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;texture-synthesis&quot;&gt;Texture Synthesis&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Sample patch(ì´ë¯¸ì§€ ì¼ë¶€)ë¡œë¶€í„° ê°™ì€ textureì˜ ë” í° ì´ë¯¸ì§€ í•©ì„±í•˜ëŠ” ë°©ì‹&lt;/li&gt;
  &lt;li&gt;nearest neighbor ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ â€˜ë³µë¶™â€™í•˜ë©´ ê¹¨ì§ í˜„ìƒì´ ìˆìŒ&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gram-matrix&quot;&gt;Gram matrix&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;imageì˜ ì§ˆê°ì˜ ìœ ì‚¬ë„ë¥¼ í‘œí˜„í•˜ëŠ” í–‰ë ¬, ì´ë¥¼ í†µí•´ texture synthesis ì§„í–‰&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_4.png&quot; alt=&quot;img_4.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ì›ë¦¬&lt;br /&gt;
1) image inputì„ CNNì— ë„£ìœ¼ë©´ C*H*W tensorê°€ ì¶œë ¥ë¨&lt;br /&gt;
2) ì´ tensor ì¤‘ 2ê°œì˜ Cì°¨ì› vectorë¥¼ ì™¸ì í•˜ë©´ C*Cì˜ co-occurenceë¥¼ í‘œí˜„í•˜ëŠ” matrixê°€ ë‚˜ì˜¤ëŠ”ë° ì´ê²ƒì´ ë°”ë¡œ Gram matrix&lt;br /&gt;
3) ë§ˆì¹˜ covarianceì„ íŒë‹¨í•˜ëŠ” í–‰ë ¬ -&amp;gt; ì§ˆê°ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì • ê°€ëŠ¥!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gram-matrix-ì´ìš©í•œ-í•©ì„±ê³¼ì •&quot;&gt;Gram matrix ì´ìš©í•œ í•©ì„±ê³¼ì •&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_5.png&quot; alt=&quot;img_5.png&quot; /&gt;
1) í•˜ë‚˜ëŠ” inputìœ¼ë¡œë¶€í„°, í•˜ë‚˜ëŠ” Noiseë¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ ìƒì„±&lt;br /&gt;
2) Gram matrix ì¶”ì¶œ í›„ Gram matrix ê°„ì— L2 distanceì˜ ê°€ì¤‘í•©, ì¦‰ Loss ê³„ì‚°&lt;br /&gt;
3) Gradient ê³„ì‚°ì„ ìœ„í•œ Backprop ë° parameter update(make gradient step)&lt;br /&gt;
4) 2)~3) ë°˜ë³µ
&lt;img src=&quot;../../assets/built/images/img9.png&quot; alt=&quot;img9.png&quot; /&gt;
-&amp;gt; ì´ ê¸°ë²• ì—­ì‹œ ê¹Šì€ Layerë¡œë¶€í„° ë” ë§ì€ featureë“¤ì´ ì¶”ì¶œë¨ì„ ì•Œ ìˆ˜ ìˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;style-transfer&quot;&gt;Style Transfer&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;ë¹„ìŠ·í•œ ë°©ë²•ìœ¼ë¡œ ë‘ ì´ë¯¸ì§€ì˜ texture ì°¨ì´ë¥¼ ìµœì†Œí™”í•¨ìœ¼ë¡œì„œ íŠ¹ì • ì´ë¯¸ì§€ì˜ ë¶„ìœ„ê¸° í•©ì„±ì´ ê°€ëŠ¥
-&amp;gt; Style transfer&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Gram matrixê°’ ìµœì†Œí™”ì‹œí‚¤ë©´ì„œ ìƒì„±í•˜ëŠ” ì´ë¯¸ì§€ ê¸°ë²•
&lt;img src=&quot;../../assets/built/images/img_6.png&quot; alt=&quot;img_6.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Content image, Style image&lt;/strong&gt;
1) content imageë¡œë¶€í„° feature reconstruction&lt;br /&gt;
2) style imageë¡œë¶€í„° gram matrix reconstruction&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;íŠ¹ì§•&lt;/strong&gt;
1) Fine control ê°€ëŠ¥(style image í¬ê¸° ì¡°ì • ë“±)&lt;br /&gt;
2) forward/backward prop ê³¼ì •ì´ ë„ˆë¬´ ë§ì•„ì„œ ëŠë¦¼.&lt;/p&gt;

    &lt;p&gt;-&amp;gt; style transferë¥¼ ì§„í–‰í•˜ëŠ” ë˜ í•˜ë‚˜ì˜ Neural Networkë¥¼ êµ¬í˜„í•˜ì!&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;fast-style-transfer&quot;&gt;Fast style Transfer&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_8.png&quot; alt=&quot;img_8.png&quot; /&gt;
1) styleì„ ë¯¸ë¦¬ &lt;strong&gt;Feedforward Network \(f_W\) ì— í•™ìŠµ&lt;/strong&gt;ì‹œí‚´&lt;br /&gt;
2) content imageë§Œ feed forward -&amp;gt; &lt;strong&gt;ì†ë„ í–¥ìƒ&lt;/strong&gt;&lt;br /&gt;
   ** batch normalizationë³´ë‹¤ instant normalization ì—ì„œ ë” í° ìƒìŠ¹ íš¨ê³¼&lt;br /&gt;
    &lt;img src=&quot;../../assets/built/images/img9.png&quot; alt=&quot;img.png&quot; /&gt;
3) segmentation networkëŠ” ì—¬ëŸ¬ ì¸µìœ¼ë¡œ transposed convolution ì´ìš©í•´ì„œ down,upsampling&lt;/p&gt;

&lt;h3 id=&quot;deepdream-websiteì—ì„œ-style-transfer-í†µí•´-ì‡ ë¼í’-ê·¸ë¦¼ìœ¼ë¡œ-êµì²´í•œ-ì‚¬ì§„&quot;&gt;Deepdream websiteì—ì„œ Style transfer í†µí•´ ì‡ ë¼í’ ê·¸ë¦¼ìœ¼ë¡œ êµì²´í•œ ì‚¬ì§„&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/built/images/img_7.png&quot; alt=&quot;img_7.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;CS231n 12ê°• Lecture Note : http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture12.pdf&lt;/li&gt;
  &lt;li&gt;https://inhovation97.tistory.com/28&lt;/li&gt;
  &lt;li&gt;style transfer : https://www.popit.kr/neural-style-transfer-%EB%94%B0%EB%9D%BC%ED%95%98%EA%B8%B0/&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>ê±´ë„ˆë³„(crosstar)</name>
        
        
      </author>

      

      
        <category term="ML" />
      

      
        <summary type="html">GOAL ì‹œê°í™”ë¥¼ í†µí•´ CNNì˜ featureë¥¼ ì´í•´í•˜ëŠ” ë°©ë²•ë¡ ë“¤ì„ activationê³¼ gradientì˜ ê´€ì ì—ì„œ ì•Œì•„ë³¸ë‹¤. ì´ë¯¸ì§€ Styleì„ ë³€í˜•ì‹œí‚¤ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤.</summary>
      

      
      
    </entry>
  
</feed>
