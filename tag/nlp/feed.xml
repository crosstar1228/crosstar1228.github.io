<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator>
  <link href="https://crosstar1228.github.io/tag/nlp/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://crosstar1228.github.io/" rel="alternate" type="text/html" />
  <updated>2022-08-31T15:44:23+00:00</updated>
  <id>https://crosstar1228.github.io/tag/nlp/feed.xml</id>

  
  
  

  
    <title type="html">건너별의 Romantic AI | </title>
  

  
    <subtitle>IT/인공지능 서랍장</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">Music Generation and AI, present and future</title>
      <link href="https://crosstar1228.github.io/NLP-music_and_ai" rel="alternate" type="text/html" title="Music Generation and AI, present and future" />
      <published>2022-07-18T11:00:00+00:00</published>
      <updated>2022-07-18T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/NLP-music_and_ai</id>
      <content type="html" xml:base="https://crosstar1228.github.io/NLP-music_and_ai">&lt;h2 id=&quot;목차&quot;&gt;목차&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://velog.io/@tobigsvoice1516/5%EC%A3%BC%EC%B0%A8-MUSIC-COMPOSITION-WITH-DEEP-LEARNING-A-REVIEW&quot;&gt;music &amp;amp; ai 역사&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://openai.com/blog/jukebox/&quot;&gt;OpenAI - JukeBox&lt;/a&gt; [&lt;a href=&quot;https://github.com/openai/jukebox/&quot;&gt;Github&lt;/a&gt;]&lt;/li&gt;
  &lt;li&gt;Datasets&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ai-music-genration의-시초&quot;&gt;AI Music Genration의 시초&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;90년대 David Bowie 의 Verbasizer (앱)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;단어를 임의로 재배치하여 음악 가사에 사용될 수 있도록 재조합하는 앱이었음&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;2016년 Sony의 App Flow Machine
    &lt;ul&gt;
      &lt;li&gt;비틀즈 스타일 멜로디를 창조해 냄&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;music-generation-도-크게-다르지-않아&quot;&gt;Music Generation 도 크게 다르지 않아&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;머신러닝에서 모델은 다량의 데이터를 학습하고 그 안에서 ‘패턴’을 찾아냅니다.&lt;/li&gt;
  &lt;li&gt;Music Generation에서는 그 패턴이 Chord, Tempo, lengths, note 간 관계성 등 이됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;symbolic-approach-non-symbolic-approach&quot;&gt;Symbolic approach, Non-symbolic approach&lt;/h3&gt;

&lt;h2 id=&quot;music-generation의-고질적인-문제-1--long-term-dependency&quot;&gt;Music Generation의 고질적인 문제 1 : LONG TERM DEPENDENCY&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;해결법 1 : autoencoder로 저차원 space로 mapping
    &lt;ul&gt;
      &lt;li&gt;불필요한 정보를 버리게 됨&lt;/li&gt;
      &lt;li&gt;이후 upsampling&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;MuseNet : midi data 기반 많은 양의 데이터 학습&lt;/li&gt;
  &lt;li&gt;Transfomer 계열 모델로 학습&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;아이디어-&quot;&gt;아이디어 :&lt;/h3&gt;
&lt;p&gt;o learn a lower-dimensional encoding of the audio with the goal of losing the less important
information but retaining most of the musical information&lt;/p&gt;
&lt;h2 id=&quot;문제-2--diversityvariation&quot;&gt;문제 2 : Diversity(variation)&lt;/h2&gt;

&lt;h3 id=&quot;jukeboxpaper&quot;&gt;JukeBox[&lt;a href=&quot;https://arxiv.org/abs/2005.00341&quot;&gt;Paper&lt;/a&gt;]&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;long context 를 autoregressiveTransformer 이용한 multi-sclae VQ-VAE로 해결&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;lyric-conditioning&quot;&gt;Lyric Conditioning&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;노래의 duration에 linear 하게 가사의 문자들을 align하는 방법&lt;/li&gt;
  &lt;li&gt;가사를 위한 encoder를 더하고, &lt;strong&gt;music decoder로부터 의 query&lt;/strong&gt;로부터 &lt;strong&gt;가사 encoder로부터의 key, value 쌍&lt;/strong&gt; 으로의 attetion layer를 적용함.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vq-vae-codebook-collapse&quot;&gt;VQ-VAE codebook collapse&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;codebook에 mapping된 embedding vector들이 많이 쓰이지 않는 현상&lt;/li&gt;
  &lt;li&gt;Random Restart:codebook vector 사용량이 평균이하로 떨어지면 , encoder output 중 하나로 다시 reset&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;https://magenta.tensorflow.org/perceiver-ar&lt;/p&gt;

&lt;h3 id=&quot;sparse-transformer&quot;&gt;Sparse Transformer&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;sparsifies the attention pattern by
reshaping the input sequence into a &lt;strong&gt;2-D sequence&lt;/strong&gt; of
shape&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;google-deepmind-202206&quot;&gt;Google Deepmind (2022.06)&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&quot;https://arxiv.org/abs/2202.07765&quot;&gt;Paper&lt;/a&gt;]&lt;/p&gt;
&lt;h3 id=&quot;perceiver-ar&quot;&gt;Perceiver AR&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;modality 에 대하여 agnostic(인지불능)인 구조
    &lt;ul&gt;
      &lt;li&gt;cross attention : long-range input -&amp;gt; small latent&lt;/li&gt;
      &lt;li&gt;maintaining end-to-end causal masking
https://soundraw.io/ 
https://magenta.tensorflow.org/
https://www.aiva.ai/
-&amp;gt; 음악 작곡&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Datasets&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;https://paperswithcode.com/task/music-generation&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;music-generation-and-deep-learning&quot;&gt;Music Generation and Deep learning&lt;/h2&gt;
&lt;p&gt;1) 딥러닝 베이스 음악 생성의 컨셉
2) 음악 생성의 다양한 방법과 원리
3) 다양한 음악 생성의 개념적 분류 체계
4) 트렌드&lt;/p&gt;

&lt;p&gt;abstract model이 generation을 위해 사용됨&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Sota models
MuseGAN
Melnet
MidiNet&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;From artificial neural networks to deep learning for music generation: history, concepts and trends&lt;/li&gt;
  &lt;li&gt;https://towardsdatascience.com/generating-music-with-artificial-intelligence-9ce3c9eef806&lt;/li&gt;
  &lt;li&gt;https://topten.ai/music-generators-review/&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name>건너별(crosstar)</name>
        
        
      </author>

      

      
        <category term="nlp" />
      

      
        <summary type="html">목차 music &amp;amp; ai 역사 OpenAI - JukeBox [Github] Datasets</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Machine learning (1) Generative Model과 GAN</title>
      <link href="https://crosstar1228.github.io/ML-GAN2" rel="alternate" type="text/html" title="Machine learning (1) Generative Model과 GAN" />
      <published>2021-09-15T11:00:00+00:00</published>
      <updated>2021-09-15T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/ML-GAN2</id>
      <content type="html" xml:base="https://crosstar1228.github.io/ML-GAN2">&lt;h1 id=&quot;안녕&quot;&gt;안녕&lt;/h1&gt;
&lt;p&gt;머신러닝 잘하고싶다.~~~~~~~~~~!!!!!!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;진짜로.&lt;/strong&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;후&lt;/code&gt;…&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>건너별(crosstar)</name>
        
        
      </author>

      

      
        <category term="nlp" />
      

      
        <summary type="html">안녕 머신러닝 잘하고싶다.~~~~~~~~~~!!!!!!</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Machine learning (1) Generative Model과 GAN</title>
      <link href="https://crosstar1228.github.io/ML-GAN" rel="alternate" type="text/html" title="Machine learning (1) Generative Model과 GAN" />
      <published>2021-09-15T11:00:00+00:00</published>
      <updated>2021-09-15T11:00:00+00:00</updated>
      <id>https://crosstar1228.github.io/ML-GAN</id>
      <content type="html" xml:base="https://crosstar1228.github.io/ML-GAN">&lt;h1 id=&quot;안녕&quot;&gt;안녕&lt;/h1&gt;
&lt;p&gt;머신러닝 잘하고싶다.~~~~~~~~~~!!!!!!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;진짜로.&lt;/strong&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;후&lt;/code&gt;…&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>건너별(crosstar)</name>
        
        
      </author>

      

      
        <category term="nlp" />
      

      
        <summary type="html">안녕 머신러닝 잘하고싶다.~~~~~~~~~~!!!!!!</summary>
      

      
      
    </entry>
  
</feed>
