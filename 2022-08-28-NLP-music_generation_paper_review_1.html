<h2 id="abstract">Abstract</h2>
<ul>
  <li>딥러닝을 활용한 최근의 다양한 음악 작곡 TASK를 소개한 논문
    <ul>
      <li>DATASETS</li>
      <li>MUSIC REPRESENTATION</li>
      <li>EVALUATION METHOD</li>
      <li>challenges &amp; future directions</li>
    </ul>
  </li>
</ul>

<h3 id="intro">Intro</h3>
<ul>
  <li><strong>음악은 언어와 같다.</strong>
    <ul>
      <li>악보 : 음악  == 글 : 말</li>
    </ul>
  </li>
  <li>
    <p>Music Generation의 대분류 3개
<img src="https://velog.velcdn.com/images/crosstar1228/post/33ed8e71-a0d8-4853-9c90-c9f1940900dc/image.png" alt="" /></p>

    <ol>
      <li>score generation</li>
      <li>performance generation add performance characteristics to scores
        <ul>
          <li>RENDERING performance</li>
          <li>composing performance</li>
        </ul>
      </li>
      <li>audio generation : convert score with performance characteristics into audio
        <ul>
          <li>assign timbre</li>
          <li>directry generate music in audio</li>
        </ul>
      </li>
    </ol>

    <p>그 중에서도 SCORE GENERATION이 가장 핫함</p>
  </li>
  <li>style transfer 적용
<img src="https://velog.velcdn.com/images/crosstar1228/post/3a730a16-e14a-4174-8d27-05807196346f/image.png" alt="" /></li>
</ul>

<h2 id="history">History</h2>
<ul>
  <li>Iliac Suite : computer 로 만들어진 최초의 score
    <ul>
      <li>Markov chain 활용(Stochastic Model)</li>
    </ul>
  </li>
</ul>

<h3 id="traditional-music-generation">Traditional Music Generation</h3>
<p>1) rule-based
    - linguistic &amp; grammar 활용
    - 음악마다 다른 rule 이 만들어져야 하는 단점
    - 
2) Probability model</p>
<ul>
  <li>semi-automatic 한 알고리즘에 Markov chain이나 이외의 기술을 태움</li>
  <li>원래의 data로부터 subsequence를 생성하지만, memory가 없어서 input에 따라 조건부 확률이 변동이 심함</li>
</ul>

<p>3) Neural Network(RNN)
    - RNN으로 feature를 학습하여 단선율의 pitch와 duration을 학습
    - Gradient Vanishing으로 long-term dependency 학습 못하는 단점</p>

<h3 id="evloutionary">evloutionary</h3>
<p>1) GenJam
2) Director Musices
3) Probablistic</p>
<ul>
  <li>hierarchical HMM</li>
  <li>dynamic Bayesian networks</li>
</ul>

<h3 id="sound-modelling">sound modelling</h3>
<ul>
  <li>physical modeling</li>
  <li>acoustic modeling : signal generator 이용
    <ul>
      <li>oscillator, modulator, filters와 같이 waveform 조작을 위한 processors</li>
      <li></li>
    </ul>
  </li>
  <li>
    <h3 id="lyrics">lyrics</h3>
  </li>
  <li>가사 포함 여부에 따라 music audio를 audio와 singing voice로 나눔.</li>
</ul>

<h2 id="deep-music-generation">Deep Music Generation</h2>
<ul>
  <li>Google Magenta : <a href="https://magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn">Melody RNN model</a></li>
  <li>Anticipation-RNN : 사용자가 정의한 positional한 제약을 강요함.</li>
  <li>TP-LSTM-NADE and BALSTM : 병렬 RNN으로부터 다선율의 데이터셋에서 translation-invariance를 유지</li>
</ul>

<h2 id="score-generation-vae-gan-transformer-">Score Generation: VAE, GAN, Transformer, …</h2>
<ul>
  <li>MusicVAE : longterm dependency, interpolation &amp; reconstruction 퍼포먼스 굳
    <ul>
      <li>coupled latent variable model</li>
      <li>binary regularizer</li>
    </ul>
  </li>
  <li>GAN
    <ul>
      <li>sequential data에는 학습에 어려움이 있음</li>
      <li>CNN based GAN으로 개발</li>
      <li>GAN-based MidiNet : Chord 에 condition되어 마디를 생성하는 알고리즘</li>
      <li>MuseGAN : multi-track 다선율 음악을 생성하는 최초의 모델
        <ul>
          <li>강화학습을 접목하여 RNN-based GAN 적용</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Transformer
    <ul>
      <li>REMI</li>
      <li>Transformer XL</li>
      <li>
        <h2 id="performance-generation--대부분-rnn">Performance Generation : 대부분 RNN</h2>
      </li>
    </ul>
  </li>
</ul>

<h2 id="representation">Representation</h2>
<p>1) symbol domain</p>
<ul>
  <li>discrete variable
2) audio domain</li>
  <li>continuous variable</li>
</ul>

<h2 id="reference">Reference</h2>
<ul>
  <li>From artificial neural networks to deep learning for music generation: history, concepts and trends</li>
  <li>https://towardsdatascience.com/generating-music-with-artificial-intelligence-9ce3c9eef806</li>
  <li>https://topten.ai/music-generators-review/</li>
</ul>
